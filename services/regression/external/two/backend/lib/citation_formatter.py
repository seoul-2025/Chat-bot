"""
Citation Formatter
ì›¹ ê²€ìƒ‰ ê²°ê³¼ì˜ ì¶œì²˜ ì •ë³´ë¥¼ í¬ë§·íŒ…í•˜ëŠ” ëª¨ë“ˆ
"""
import re
import logging
from typing import List, Dict, Tuple
from urllib.parse import urlparse

logger = logging.getLogger(__name__)


class CitationFormatter:
    """ì¶œì²˜ í‘œì‹œ ë° í¬ë§·íŒ…ì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤"""
    
    # ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì–¸ë¡ ì‚¬ ë„ë©”ì¸
    TRUSTED_NEWS_DOMAINS = {
        'ytn.co.kr': 'âœ… YTN',
        'joins.com': 'âœ… ì¤‘ì•™ì¼ë³´',
        'chosun.com': 'âœ… ì¡°ì„ ì¼ë³´',
        'donga.com': 'âœ… ë™ì•„ì¼ë³´',
        'hani.co.kr': 'âœ… í•œê²¨ë ˆ',
        'khan.co.kr': 'âœ… ê²½í–¥ì‹ ë¬¸',
        'mt.co.kr': 'âœ… ë¨¸ë‹ˆíˆ¬ë°ì´',
        'hankyung.com': 'âœ… í•œêµ­ê²½ì œ',
        'mk.co.kr': 'âœ… ë§¤ì¼ê²½ì œ',
        'seoul.co.kr': 'âœ… ì„œìš¸ì‹ ë¬¸',
        'kbs.co.kr': 'âœ… KBS',
        'mbc.co.kr': 'âœ… MBC',
        'sbs.co.kr': 'âœ… SBS',
        'jtbc.joins.com': 'âœ… JTBC'
    }
    
    # ì •ë¶€/ê³µê³µê¸°ê´€ ë„ë©”ì¸
    GOVERNMENT_DOMAINS = {
        'go.kr': 'ğŸ›ï¸',
        'korea.kr': 'ğŸ›ï¸'
    }
    
    @staticmethod
    def format_response_with_citations(text: str, search_results: List[Dict] = None) -> str:
        """
        AI ì‘ë‹µì—ì„œ URLì„ ê°ì§€í•˜ê³  ì¶œì²˜ ê°ì£¼ë¡œ ë³€í™˜
        
        Args:
            text: AI ì‘ë‹µ í…ìŠ¤íŠ¸
            search_results: ì›¹ ê²€ìƒ‰ ê²°ê³¼ (ì˜µì…˜)
        
        Returns:
            ì¶œì²˜ê°€ í¬í•¨ëœ í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸
        """
        try:
            # URL íŒ¨í„´ ë§¤ì¹­
            url_pattern = r'https?://[^\s\])]+'
            urls = re.findall(url_pattern, text)
            
            if not urls and not search_results:
                return text
            
            # ê°ì£¼ ë²ˆí˜¸ì™€ URL ë§¤í•‘
            citations = []
            citation_map = {}
            
            # í…ìŠ¤íŠ¸ì—ì„œ ì°¾ì€ URLë“¤ ì²˜ë¦¬
            for i, url in enumerate(urls, 1):
                if url not in citation_map:
                    citation_info = CitationFormatter._extract_domain_info(url)
                    citations.append({
                        'number': i,
                        'url': url,
                        'domain': citation_info['domain'],
                        'trust_level': citation_info['trust_level'],
                        'title': f"ì°¸ì¡° {i}"
                    })
                    citation_map[url] = i
            
            # ì›¹ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì¶”ê°€ ì¶œì²˜ ì²˜ë¦¬
            if search_results:
                for result in search_results:
                    url = result.get('url', '')
                    if url and url not in citation_map:
                        next_num = len(citations) + 1
                        citation_info = CitationFormatter._extract_domain_info(url)
                        citations.append({
                            'number': next_num,
                            'url': url,
                            'domain': citation_info['domain'],
                            'trust_level': citation_info['trust_level'],
                            'title': result.get('title', f"ì°¸ì¡° {next_num}")
                        })
                        citation_map[url] = next_num
            
            # í…ìŠ¤íŠ¸ì—ì„œ URLì„ ê°ì£¼ ë²ˆí˜¸ë¡œ ëŒ€ì²´
            formatted_text = text
            for url, number in citation_map.items():
                formatted_text = formatted_text.replace(url, f"[{number}]")
            
            # ì¶œì²˜ ì„¹ì…˜ ìƒì„±
            if citations:
                sources_section = CitationFormatter._build_sources_section(citations)
                formatted_text += "\n\n" + sources_section
            
            return formatted_text
            
        except Exception as e:
            logger.error(f"Error formatting citations: {str(e)}")
            return text  # ì˜¤ë¥˜ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜
    
    @staticmethod
    def _extract_domain_info(url: str) -> Dict[str, str]:
        """
        URLì—ì„œ ë„ë©”ì¸ ì •ë³´ ì¶”ì¶œ ë° ì‹ ë¢°ë„ íŒë‹¨
        
        Args:
            url: ë¶„ì„í•  URL
            
        Returns:
            ë„ë©”ì¸ ì •ë³´ì™€ ì‹ ë¢°ë„
        """
        try:
            parsed = urlparse(url)
            domain = parsed.netloc.lower()
            
            # ì •í™•í•œ ë„ë©”ì¸ ë§¤ì¹­
            if domain in CitationFormatter.TRUSTED_NEWS_DOMAINS:
                return {
                    'domain': domain,
                    'trust_level': CitationFormatter.TRUSTED_NEWS_DOMAINS[domain]
                }
            
            # ì •ë¶€/ê³µê³µê¸°ê´€ ë„ë©”ì¸ ì²´í¬
            for gov_domain in CitationFormatter.GOVERNMENT_DOMAINS:
                if domain.endswith(gov_domain):
                    return {
                        'domain': domain,
                        'trust_level': f"{CitationFormatter.GOVERNMENT_DOMAINS[gov_domain]} ê³µê³µê¸°ê´€"
                    }
            
            # ì¼ë°˜ ì›¹ì‚¬ì´íŠ¸
            return {
                'domain': domain,
                'trust_level': 'â„¹ï¸ ì¼ë°˜'
            }
            
        except Exception as e:
            logger.error(f"Error parsing domain from {url}: {str(e)}")
            return {
                'domain': 'unknown',
                'trust_level': 'â„¹ï¸ ì¼ë°˜'
            }
    
    @staticmethod
    def _build_sources_section(citations: List[Dict]) -> str:
        """
        ì¶œì²˜ ì„¹ì…˜ì„ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ìƒì„±
        
        Args:
            citations: ì¶œì²˜ ì •ë³´ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            í¬ë§·íŒ…ëœ ì¶œì²˜ ì„¹ì…˜
        """
        if not citations:
            return ""
        
        lines = [
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
            "ğŸ“š **ì¶œì²˜:**"
        ]
        
        for citation in citations:
            line = f"[{citation['number']}] {citation['trust_level']} {citation['title']} - {citation['url']}"
            lines.append(line)
        
        lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        
        return "\n".join(lines)
    
    @staticmethod
    def extract_citations_from_web_search(search_response: str) -> List[Dict]:
        """
        ì›¹ ê²€ìƒ‰ ì‘ë‹µì—ì„œ ì¶œì²˜ ì •ë³´ ì¶”ì¶œ
        
        Args:
            search_response: ì›¹ ê²€ìƒ‰ API ì‘ë‹µ
            
        Returns:
            ì¶”ì¶œëœ ì¶œì²˜ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # Anthropic ì›¹ ê²€ìƒ‰ ì‘ë‹µì—ì„œ citation ì •ë³´ ì¶”ì¶œ
            citations = []
            
            # URL íŒ¨í„´ìœ¼ë¡œ ê¸°ë³¸ ì¶”ì¶œ
            url_pattern = r'https?://[^\s\])]+'
            urls = re.findall(url_pattern, search_response)
            
            for i, url in enumerate(set(urls), 1):  # ì¤‘ë³µ ì œê±°
                citation_info = CitationFormatter._extract_domain_info(url)
                citations.append({
                    'number': i,
                    'url': url,
                    'domain': citation_info['domain'],
                    'trust_level': citation_info['trust_level'],
                    'title': f"ì›¹ ê²€ìƒ‰ ê²°ê³¼ {i}"
                })
            
            return citations
            
        except Exception as e:
            logger.error(f"Error extracting citations from search response: {str(e)}")
            return []