"""
WebSocket Service
WebSocket ë©”ì‹œì§€ ì²˜ë¦¬ ë° Bedrock í†µí•© ì„œë¹„ìŠ¤
"""
import json
import boto3
import logging
import time
import os
from datetime import datetime
from decimal import Decimal
from typing import List, Dict, Any, Optional, Generator, Tuple
import uuid

from handlers.websocket.conversation_manager import ConversationManager
from lib.bedrock_client_enhanced import BedrockClientEnhanced
from lib.anthropic_client import AnthropicClient, create_enhanced_system_prompt
from lib.citation_formatter import CitationFormatter
from utils.logger import setup_logger

# Logger ì´ˆê¸°í™”
logger = setup_logger(__name__)

# DynamoDB í´ë¼ì´ì–¸íŠ¸
dynamodb = boto3.resource('dynamodb', region_name='us-east-1')
prompts_table = dynamodb.Table('nx-tt-dev-ver3-prompts')
usage_table = dynamodb.Table('nx-tt-dev-ver3-usage-tracking')

# í”„ë¡¬í”„íŠ¸ ìºì‹œ (Lambda ì»¨í…Œì´ë„ˆ ì¬ì‚¬ìš© ì‹œ ìœ ì§€ - ì˜êµ¬ ìºì‹œ)
PROMPT_CACHE: Dict[str, Dict[str, Any]] = {}


class WebSocketService:
    """WebSocket ë©”ì‹œì§€ ì²˜ë¦¬ ì„œë¹„ìŠ¤"""

    # í† í°ë‹¹ ì˜ˆìƒ ë¹„ìš© (USD)
    COST_PER_1K_INPUT_TOKENS = {
        'T5': Decimal('0.003'),
        'H8': Decimal('0.015')
    }
    COST_PER_1K_OUTPUT_TOKENS = {
        'T5': Decimal('0.015'),
        'H8': Decimal('0.075')
    }

    def __init__(self):
        # AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (í™˜ê²½ë³€ìˆ˜ì— ë”°ë¼ ì„ íƒ)
        use_anthropic = os.environ.get('USE_ANTHROPIC_API', 'false').lower() == 'true'
        if use_anthropic:
            self.ai_client = AnthropicClient()
            self.ai_provider = 'anthropic'
            logger.info("Using Anthropic API (Claude 4.5 Opus)")
        else:
            self.ai_client = BedrockClientEnhanced()
            self.ai_provider = 'bedrock'
            logger.info("Using AWS Bedrock (Claude 3.5 Sonnet)")
        
        # Bedrock í´ë¼ì´ì–¸íŠ¸ë„ í´ë°±ìš©ìœ¼ë¡œ ìœ ì§€
        self.bedrock_client = BedrockClientEnhanced()
        self.conversation_manager = ConversationManager()
        self.citation_formatter = CitationFormatter()
        self.prompts_table = prompts_table
        self.usage_table = usage_table
        logger.info("WebSocketService initialized")
    
    def process_message(
        self,
        user_message: str,
        engine_type: str,
        conversation_id: Optional[str],
        user_id: str,
        conversation_history: List[Dict],
        user_role: str = 'user'
    ) -> Dict[str, Any]:
        """
        ë©”ì‹œì§€ ì²˜ë¦¬ ë° ëŒ€í™” íˆìŠ¤í† ë¦¬ ë³‘í•©
        
        Returns:
            Dict containing conversation_id and merged_history
        """
        try:
            # ëŒ€í™” IDê°€ ì—†ìœ¼ë©´ ìƒì„±
            if not conversation_id:
                conversation_id = str(uuid.uuid4())
                logger.info(f"New conversation created: {conversation_id}")
            
            # DBì—ì„œ ê¸°ì¡´ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ
            db_history = self.conversation_manager.get_conversation_history(
                conversation_id, 
                limit=20  # ìµœê·¼ 20ê°œ ë©”ì‹œì§€
                ## ëŒ€í™”ê¸°ì–µê¸°ëŠ¥
            )
            
            # í´ë¼ì´ì–¸íŠ¸ íˆìŠ¤í† ë¦¬ì™€ DB íˆìŠ¤í† ë¦¬ ë³‘í•©
            merged_history = self._merge_conversation_history(
                client_history=conversation_history,
                db_history=db_history
            )
            
            # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™”ì— ì €ì¥
            self.conversation_manager.save_message(
                conversation_id=conversation_id,
                role='user',
                content=user_message,
                engine_type=engine_type,
                user_id=user_id
            )
            
            # ë³‘í•©ëœ íˆìŠ¤í† ë¦¬ì— í˜„ì¬ ë©”ì‹œì§€ ì¶”ê°€
            merged_history.append({
                'role': 'user',
                'content': user_message,
                'timestamp': datetime.utcnow().isoformat() + 'Z'
            })
            
            logger.info(f"Processed message for conversation {conversation_id}")
            logger.info(f"Merged history length: {len(merged_history)}")
            
            return {
                'conversation_id': conversation_id,
                'merged_history': merged_history
            }
            
        except Exception as e:
            logger.error(f"Error processing message: {str(e)}")
            raise
    
    def _load_prompt_from_dynamodb(self, engine_type: str) -> Dict[str, Any]:
        """
        DynamoDBì—ì„œ í”„ë¡¬í”„íŠ¸ì™€ íŒŒì¼ ë¡œë“œ (ì¸ë©”ëª¨ë¦¬ ì˜êµ¬ ìºì‹± ì ìš©)

        ìºì‹± ì „ëµ:
        - ì˜êµ¬ ìºì‹œ: Lambda ì»¨í…Œì´ë„ˆ ìˆ˜ëª… ë™ì•ˆ ìœ ì§€
        - DB ì¡°íšŒ: ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘ ì‹œì—ë§Œ
        - ëŒ€ëŸ‰ ë¬¸ì„œ ì¡°íšŒ ë¹„ìš© ëŒ€í­ ì ˆê°
        """
        global PROMPT_CACHE

        try:
            # ìºì‹œ í™•ì¸ (ì˜êµ¬ ìºì‹œ)
            if engine_type in PROMPT_CACHE:
                logger.info(f"âœ… Cache HIT for {engine_type} - DB query skipped")
                return PROMPT_CACHE[engine_type]
            
            logger.info(f"âŒ Cache MISS for {engine_type} - fetching from DB")

            # ìºì‹œ ë¯¸ìŠ¤ - DBì—ì„œ ë¡œë“œ
            prompt_data = self._fetch_prompt_from_db(engine_type)

            # ìºì‹œ ì—…ë°ì´íŠ¸ (ì˜êµ¬ ì €ì¥)
            PROMPT_CACHE[engine_type] = prompt_data
            logger.info(f"ğŸ’¾ Permanently cached prompt for {engine_type} "
                       f"({len(prompt_data.get('files', []))} files, "
                       f"{len(str(prompt_data))} bytes)")

            return prompt_data

        except Exception as e:
            logger.error(f"Error loading prompt: {str(e)}")
            return {'instruction': '', 'description': '', 'files': []}

    def _fetch_prompt_from_db(self, engine_type: str) -> Dict[str, Any]:
        """
        ì‹¤ì œ DB ì¡°íšŒ ë¡œì§ (ìºì‹± ì „ìš©)
        ìºì‹œ ë¯¸ìŠ¤ ì‹œì—ë§Œ í˜¸ì¶œë¨
        """
        try:
            start_time = time.time()

            # í”„ë¡¬í”„íŠ¸ í…Œì´ë¸”ì—ì„œ ê¸°ë³¸ ì •ë³´ ë¡œë“œ
            response = self.prompts_table.get_item(Key={'id': engine_type})
            if 'Item' in response:
                item = response['Item']
                prompt_data = {
                    'instruction': item.get('instruction', ''),
                    'description': item.get('description', ''),
                    'files': []
                }

                # files í…Œì´ë¸”ì—ì„œ ê´€ë ¨ íŒŒì¼ë“¤ ë¡œë“œ
                try:
                    files_table = dynamodb.Table('nx-tt-dev-ver3-files')
                    files_response = files_table.scan(
                        FilterExpression='promptId = :promptId',
                        ExpressionAttributeValues={':promptId': engine_type}
                    )

                    if 'Items' in files_response:
                        for file_item in files_response['Items']:
                            prompt_data['files'].append({
                                'fileName': file_item.get('fileName', ''),
                                'fileContent': file_item.get('fileContent', ''),
                                'fileType': 'text'  # ê¸°ë³¸ê°’
                            })

                        elapsed = (time.time() - start_time) * 1000
                        logger.info(f"ğŸ” DB fetch for {engine_type}: "
                                  f"{len(prompt_data['files'])} files in {elapsed:.0f}ms")
                except Exception as fe:
                    logger.error(f"Error loading files: {str(fe)}")

                return prompt_data
            else:
                logger.warning(f"No prompt found for engine type: {engine_type}")
                return {'instruction': '', 'description': '', 'files': []}
        except Exception as e:
            logger.error(f"Error fetching from DB: {str(e)}")
            return {'instruction': '', 'description': '', 'files': []}

    def stream_response(
        self,
        user_message: str,
        engine_type: str,
        conversation_id: str,
        user_id: str,
        conversation_history: List[Dict],
        user_role: str = 'user'
    ) -> Generator[str, None, None]:
        """
        Bedrock ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±

        Yields:
            str: ì‘ë‹µ ì²­í¬
        """
        try:
            # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
            formatted_history = self._format_conversation_for_bedrock(conversation_history)

            # DynamoDBì—ì„œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ (ì˜êµ¬ ìºì‹± ì ìš©)
            prompt_data = self._load_prompt_from_dynamodb(engine_type)

            logger.info(f"Loaded prompt for {engine_type}: instruction={len(prompt_data.get('instruction', ''))} chars")
            logger.info(f"Streaming response for engine {engine_type}")
            logger.info(f"Conversation context: {len(formatted_history)} messages")
            
            # AI ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ (Anthropic ë˜ëŠ” Bedrock)
            total_response = ""
            
            # ì›¹ ê²€ìƒ‰ í™œì„±í™” ì—¬ë¶€ í™•ì¸
            enable_web_search = os.environ.get('ENABLE_NATIVE_WEB_SEARCH', 'true').lower() == 'true'
            
            # Anthropic API ì‚¬ìš© ì‹œ
            if self.ai_provider == 'anthropic' and hasattr(self.ai_client, 'stream_response'):
                try:
                    logger.info(f"Using Anthropic API for {engine_type} (web_search: {enable_web_search})")

                    # ì²´ê³„ì ì¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„± (CoT ê¸°ë°˜)
                    # ìºì‹± ìµœì í™”: system_promptëŠ” ì •ì ìœ¼ë¡œ ìœ ì§€, ëŒ€í™” íˆìŠ¤í† ë¦¬ëŠ” ë³„ë„ë¡œ ì „ë‹¬
                    full_system_prompt = create_enhanced_system_prompt(
                        prompt_data=prompt_data,
                        engine_type=engine_type,
                        user_role=user_role
                    )

                    for chunk in self.ai_client.stream_response(
                        user_message=user_message,
                        system_prompt=full_system_prompt,
                        conversation_history=conversation_history,  # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ë³„ë„ë¡œ ì „ë‹¬
                        enable_web_search=enable_web_search,
                        enable_caching=True  # í”„ë¡¬í”„íŠ¸ ìºì‹± í™œì„±í™”
                    ):
                        total_response += chunk
                        yield chunk
                        
                except Exception as e:
                    # Anthropic API ì‹¤íŒ¨ ì‹œ Bedrockìœ¼ë¡œ í´ë°±
                    if os.environ.get('FALLBACK_TO_BEDROCK', 'true').lower() == 'true':
                        logger.warning(f"Anthropic API failed, falling back to Bedrock: {str(e)}")
                        total_response = ""
                        for chunk in self.bedrock_client.stream_bedrock(
                            user_message=user_message,
                            engine_type=engine_type,
                            conversation_context=formatted_history,
                            user_role=user_role,
                            guidelines=prompt_data.get('instruction'),
                            description=prompt_data.get('description'),
                            files=prompt_data.get('files', [])
                        ):
                            total_response += chunk
                            yield chunk
                    else:
                        raise
            
            # Bedrock ì‚¬ìš© ì‹œ (ê¸°ì¡´ ë¡œì§)
            else:
                for chunk in self.bedrock_client.stream_bedrock(
                    user_message=user_message,
                    engine_type=engine_type,
                    conversation_context=formatted_history,  # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬
                    user_role=user_role,
                    guidelines=prompt_data.get('instruction'),  # DynamoDB instruction ì „ë‹¬
                    description=prompt_data.get('description'),  # DynamoDB description ì „ë‹¬
                    files=prompt_data.get('files', [])  # DynamoDB files ì „ë‹¬
                ):
                    total_response += chunk
                    yield chunk
            
            # ì›¹ ê²€ìƒ‰ ì¶œì²˜ í¬ë§·íŒ… ì ìš© (Anthropic API ì‚¬ìš© ì‹œ)
            if total_response and self.ai_provider == 'anthropic' and enable_web_search:
                # ì¶œì²˜ê°€ ìë™ìœ¼ë¡œ í¬í•¨ë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ í¬ë§·íŒ… ì ìš©
                if "ğŸ“š ì¶œì²˜:" not in total_response and "http" in total_response:
                    formatted_response = self.citation_formatter.format_response_with_citations(total_response)
                    total_response = formatted_response
                    logger.info("Citation formatting applied")
            
            # AI ì‘ë‹µì„ ëŒ€í™”ì— ì €ì¥
            if total_response:
                self.conversation_manager.save_message(
                    conversation_id=conversation_id,
                    role='assistant',
                    content=total_response,
                    engine_type=engine_type,
                    user_id=user_id
                )
                logger.info(f"AI response saved: {len(total_response)} chars")
            
        except Exception as e:
            logger.error(f"Error streaming response: {str(e)}")
            raise
    
    def clear_history(self, conversation_id: str) -> bool:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"""
        try:
            # ìƒˆë¡œìš´ ëŒ€í™”ë¡œ ì¬ìƒì„±
            self.conversation_manager.create_or_update_conversation(
                conversation_id=conversation_id,
                title="Cleared conversation"
            )
            logger.info(f"Cleared history for conversation {conversation_id}")
            return True
        except Exception as e:
            logger.error(f"Error clearing history: {str(e)}")
            return False
    
    def track_usage(
        self,
        user_id: str,
        engine_type: str,
        input_text: str,
        output_text: str
    ) -> None:
        """ì‚¬ìš©ëŸ‰ ì¶”ì """
        try:
            # í† í° ê³„ì‚° (ê°„ë‹¨í•œ ì¶”ì •)
            input_tokens = int(len(input_text.split()) * 1.3)
            output_tokens = int(len(output_text.split()) * 1.3)
            total_tokens = input_tokens + output_tokens

            # í˜„ì¬ ë…„ì›” (YYYY-MM)
            now = datetime.now()
            year_month = now.strftime('%Y-%m')

            # DynamoDB í‚¤ (ì‹¤ì œ í…Œì´ë¸” êµ¬ì¡°ì— ë§ì¶¤)
            pk = f"user#{user_id}"
            sk = f"engine#{engine_type}#{year_month}"

            # ì—…ë°ì´íŠ¸
            self.usage_table.update_item(
                Key={
                    'PK': pk,
                    'SK': sk
                },
                UpdateExpression="""
                    SET messageCount = if_not_exists(messageCount, :zero) + :one,
                        inputTokens = if_not_exists(inputTokens, :zero) + :input,
                        outputTokens = if_not_exists(outputTokens, :zero) + :output,
                        totalTokens = if_not_exists(totalTokens, :zero) + :total,
                        engineType = :engine,
                        userId = :userId,
                        yearMonth = :yearMonth,
                        updatedAt = :now,
                        lastUsedAt = :now
                """,
                ExpressionAttributeValues={
                    ':zero': 0,
                    ':one': 1,
                    ':input': input_tokens,
                    ':output': output_tokens,
                    ':total': total_tokens,
                    ':engine': engine_type,
                    ':userId': user_id,
                    ':yearMonth': year_month,
                    ':now': now.isoformat()
                }
            )

            logger.info(f"Usage tracked: {user_id}, {engine_type}, "
                       f"tokens={input_tokens}+{output_tokens}")

        except Exception as e:
            logger.error(f"Error tracking usage: {str(e)}", exc_info=True)
    
    def _merge_conversation_history(
        self,
        client_history: List[Dict],
        db_history: List[Dict]
    ) -> List[Dict]:
        """
        í´ë¼ì´ì–¸íŠ¸ì™€ DBì˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ ë³‘í•©
        
        DB íˆìŠ¤í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•˜ë˜, í´ë¼ì´ì–¸íŠ¸ íˆìŠ¤í† ë¦¬ì—ë§Œ ìˆëŠ” ë©”ì‹œì§€ëŠ” ì¶”ê°€
        """
        merged = []
        
        # DB íˆìŠ¤í† ë¦¬ë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©
        for msg in db_history:
            merged.append({
                'role': msg.get('role', msg.get('type', 'user')),
                'content': msg.get('content', ''),
                'timestamp': msg.get('timestamp', '')
            })
        
        # í´ë¼ì´ì–¸íŠ¸ íˆìŠ¤í† ë¦¬ì—ë§Œ ìˆëŠ” ë©”ì‹œì§€ í™•ì¸ ë° ì¶”ê°€
        db_timestamps = {msg.get('timestamp') for msg in db_history if msg.get('timestamp')}
        
        for msg in client_history:
            timestamp = msg.get('timestamp')
            # íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ì—†ê±°ë‚˜ DBì— ì—†ëŠ” ë©”ì‹œì§€ëŠ” ìƒˆë¡œìš´ ë©”ì‹œì§€ë¡œ ê°„ì£¼
            if not timestamp or timestamp not in db_timestamps:
                # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ìµœê·¼ ë©”ì‹œì§€ì™€ ë¹„êµ
                content = msg.get('content', '')
                if not merged or merged[-1].get('content') != content:
                    merged.append({
                        'role': msg.get('role', 'user'),
                        'content': content,
                        'timestamp': timestamp or datetime.utcnow().isoformat() + 'Z'
                    })
        
        # ìµœëŒ€ 30ê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€ (ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ê´€ë¦¬) #ëŒ€í™”ê¸°ì–µê¸°ëŠ¥
        if len(merged) > 30:
            merged = merged[-30:]
        
        return merged

    def _format_conversation_for_bedrock(self, conversation_history: List[Dict]) -> str:
        """
        Bedrockì— ì „ë‹¬í•  ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…
        """
        if not conversation_history:
            return ""
        
        formatted_messages = []
        for msg in conversation_history[-10:]:  # ìµœê·¼ 10ê°œ ë©”ì‹œì§€ë§Œ ì‚¬ìš© #ëŒ€í™”ê¸°ì–µê¸°ëŠ¥
            role = msg.get('role', 'user')
            content = msg.get('content', '')
            
            if content:
                if role == 'user':
                    formatted_messages.append(f"ì‚¬ìš©ì: {content}")
                elif role == 'assistant':
                    formatted_messages.append(f"AI: {content}")
        
        if formatted_messages:
            return "\n\n=== ì´ì „ ëŒ€í™” ë‚´ìš© ===\n" + "\n\n".join(formatted_messages) + "\n\n=== í˜„ì¬ ì§ˆë¬¸ ==="
        
        return ""