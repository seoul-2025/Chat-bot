"""
WebSocket Service
WebSocket ë©”ì‹œì§€ ì²˜ë¦¬ ë° Bedrock í†µí•© ì„œë¹„ìŠ¤
"""
import json
import boto3
import logging
import time
import os
from datetime import datetime
from decimal import Decimal
from typing import List, Dict, Any, Optional, Generator, Tuple
import uuid

from handlers.websocket.conversation_manager import ConversationManager
from lib.bedrock_client_enhanced import BedrockClientEnhanced
from lib.anthropic_client import AnthropicClient
from lib.citation_formatter import CitationFormatter
from utils.logger import setup_logger

# RAG ê¸°ëŠ¥ (ì„ íƒì  import)
try:
    from lib.vector_search import get_vector_search
    RAG_AVAILABLE = True
    logger = setup_logger(__name__)
    logger.info("âœ… RAG ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    RAG_AVAILABLE = False
    logger = setup_logger(__name__)
    logger.warning(f"âš ï¸  RAG ëª¨ë“ˆ ì—†ìŒ: {str(e)}")

# DynamoDB í´ë¼ì´ì–¸íŠ¸
dynamodb = boto3.resource('dynamodb', region_name='us-east-1')
prompts_table = dynamodb.Table('nx-tt-dev-ver3-prompts')
usage_table = dynamodb.Table('nx-tt-dev-ver3-usage-tracking')

# í”„ë¡¬í”„íŠ¸ ìºì‹œ (Lambda ì»¨í…Œì´ë„ˆ ì¬ì‚¬ìš© ì‹œ ìœ ì§€ - ì˜êµ¬ ìºì‹œ)
PROMPT_CACHE: Dict[str, Dict[str, Any]] = {}


class WebSocketService:
    """WebSocket ë©”ì‹œì§€ ì²˜ë¦¬ ì„œë¹„ìŠ¤"""

    # í† í°ë‹¹ ì˜ˆìƒ ë¹„ìš© (USD)
    COST_PER_1K_INPUT_TOKENS = {
        'T5': Decimal('0.003'),
        'H8': Decimal('0.015')
    }
    COST_PER_1K_OUTPUT_TOKENS = {
        'T5': Decimal('0.015'),
        'H8': Decimal('0.075')
    }

    def __init__(self):
        # AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (í™˜ê²½ë³€ìˆ˜ì— ë”°ë¼ ì„ íƒ)
        use_anthropic = os.environ.get('USE_ANTHROPIC_API', 'false').lower() == 'true'
        if use_anthropic:
            self.ai_client = AnthropicClient()
            self.ai_provider = 'anthropic'
            logger.info("Using Anthropic API (Claude 4.5 Opus)")
        else:
            self.ai_client = BedrockClientEnhanced()
            self.ai_provider = 'bedrock'
            logger.info("Using AWS Bedrock (Claude 3.5 Sonnet)")
        
        # Bedrock í´ë¼ì´ì–¸íŠ¸ë„ í´ë°±ìš©ìœ¼ë¡œ ìœ ì§€
        self.bedrock_client = BedrockClientEnhanced()
        self.conversation_manager = ConversationManager()
        self.citation_formatter = CitationFormatter()
        self.prompts_table = prompts_table
        self.usage_table = usage_table
        logger.info("WebSocketService initialized")
    
    def process_message(
        self,
        user_message: str,
        engine_type: str,
        conversation_id: Optional[str],
        user_id: str,
        conversation_history: List[Dict],
        user_role: str = 'user'
    ) -> Dict[str, Any]:
        """
        ë©”ì‹œì§€ ì²˜ë¦¬ ë° ëŒ€í™” íˆìŠ¤í† ë¦¬ ë³‘í•©
        
        Returns:
            Dict containing conversation_id and merged_history
        """
        try:
            # ëŒ€í™” IDê°€ ì—†ìœ¼ë©´ ìƒì„±
            if not conversation_id:
                conversation_id = str(uuid.uuid4())
                logger.info(f"New conversation created: {conversation_id}")
            
            # DBì—ì„œ ê¸°ì¡´ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ
            db_history = self.conversation_manager.get_conversation_history(
                conversation_id, 
                limit=20  # ìµœê·¼ 20ê°œ ë©”ì‹œì§€
                ## ëŒ€í™”ê¸°ì–µê¸°ëŠ¥
            )
            
            # í´ë¼ì´ì–¸íŠ¸ íˆìŠ¤í† ë¦¬ì™€ DB íˆìŠ¤í† ë¦¬ ë³‘í•©
            merged_history = self._merge_conversation_history(
                client_history=conversation_history,
                db_history=db_history
            )
            
            # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™”ì— ì €ì¥
            self.conversation_manager.save_message(
                conversation_id=conversation_id,
                role='user',
                content=user_message,
                engine_type=engine_type,
                user_id=user_id
            )
            
            # ë³‘í•©ëœ íˆìŠ¤í† ë¦¬ì— í˜„ì¬ ë©”ì‹œì§€ ì¶”ê°€
            merged_history.append({
                'role': 'user',
                'content': user_message,
                'timestamp': datetime.utcnow().isoformat() + 'Z'
            })
            
            logger.info(f"Processed message for conversation {conversation_id}")
            logger.info(f"Merged history length: {len(merged_history)}")
            
            return {
                'conversation_id': conversation_id,
                'merged_history': merged_history
            }
            
        except Exception as e:
            logger.error(f"Error processing message: {str(e)}")
            raise
    
    def _load_prompt_from_dynamodb(self, engine_type: str) -> Dict[str, Any]:
        """
        DynamoDBì—ì„œ í”„ë¡¬í”„íŠ¸ì™€ íŒŒì¼ ë¡œë“œ (ì¸ë©”ëª¨ë¦¬ ì˜êµ¬ ìºì‹± ì ìš©)

        ìºì‹± ì „ëµ:
        - ì˜êµ¬ ìºì‹œ: Lambda ì»¨í…Œì´ë„ˆ ìˆ˜ëª… ë™ì•ˆ ìœ ì§€
        - DB ì¡°íšŒ: ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘ ì‹œì—ë§Œ
        - ëŒ€ëŸ‰ ë¬¸ì„œ ì¡°íšŒ ë¹„ìš© ëŒ€í­ ì ˆê°
        """
        global PROMPT_CACHE

        try:
            # ìºì‹œ í™•ì¸ (ì˜êµ¬ ìºì‹œ)
            if engine_type in PROMPT_CACHE:
                logger.info(f"âœ… Cache HIT for {engine_type} - DB query skipped")
                return PROMPT_CACHE[engine_type]
            
            logger.info(f"âŒ Cache MISS for {engine_type} - fetching from DB")

            # ìºì‹œ ë¯¸ìŠ¤ - DBì—ì„œ ë¡œë“œ
            prompt_data = self._fetch_prompt_from_db(engine_type)

            # ìºì‹œ ì—…ë°ì´íŠ¸ (ì˜êµ¬ ì €ì¥)
            PROMPT_CACHE[engine_type] = prompt_data
            logger.info(f"ğŸ’¾ Permanently cached prompt for {engine_type} "
                       f"({len(prompt_data.get('files', []))} files, "
                       f"{len(str(prompt_data))} bytes)")

            return prompt_data

        except Exception as e:
            logger.error(f"Error loading prompt: {str(e)}")
            return {'instruction': '', 'description': '', 'files': []}

    def _fetch_prompt_from_db(self, engine_type: str) -> Dict[str, Any]:
        """
        ì‹¤ì œ DB ì¡°íšŒ ë¡œì§ (ìºì‹± ì „ìš©)
        ìºì‹œ ë¯¸ìŠ¤ ì‹œì—ë§Œ í˜¸ì¶œë¨
        """
        try:
            start_time = time.time()

            # í”„ë¡¬í”„íŠ¸ í…Œì´ë¸”ì—ì„œ ê¸°ë³¸ ì •ë³´ ë¡œë“œ
            response = self.prompts_table.get_item(Key={'id': engine_type})
            if 'Item' in response:
                item = response['Item']
                prompt_data = {
                    'instruction': item.get('instruction', ''),
                    'description': item.get('description', ''),
                    'files': []
                }

                # files í…Œì´ë¸”ì—ì„œ ê´€ë ¨ íŒŒì¼ë“¤ ë¡œë“œ
                try:
                    files_table = dynamodb.Table('nx-tt-dev-ver3-files')
                    files_response = files_table.scan(
                        FilterExpression='promptId = :promptId',
                        ExpressionAttributeValues={':promptId': engine_type}
                    )

                    if 'Items' in files_response:
                        for file_item in files_response['Items']:
                            prompt_data['files'].append({
                                'fileName': file_item.get('fileName', ''),
                                'fileContent': file_item.get('fileContent', ''),
                                'fileType': 'text'  # ê¸°ë³¸ê°’
                            })

                        elapsed = (time.time() - start_time) * 1000
                        logger.info(f"ğŸ” DB fetch for {engine_type}: "
                                  f"{len(prompt_data['files'])} files in {elapsed:.0f}ms")
                except Exception as fe:
                    logger.error(f"Error loading files: {str(fe)}")

                return prompt_data
            else:
                logger.warning(f"No prompt found for engine type: {engine_type}")
                return {'instruction': '', 'description': '', 'files': []}
        except Exception as e:
            logger.error(f"Error fetching from DB: {str(e)}")
            return {'instruction': '', 'description': '', 'files': []}

    def _create_rag_enhanced_prompt(
        self,
        user_message: str,
        engine_type: str
    ) -> Dict[str, Any]:
        """
        RAGë¡œ ê´€ë ¨ í”„ë¡¬í”„íŠ¸ ì²­í¬ë¥¼ ê²€ìƒ‰í•˜ì—¬ ë™ì ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±

        Args:
            user_message: ì‚¬ìš©ì ì…ë ¥ (ê¸°ì‚¬ ë‚´ìš©)
            engine_type: ì—”ì§„ íƒ€ì…

        Returns:
            RAGë¡œ êµ¬ì„±ëœ í”„ë¡¬í”„íŠ¸ ë°ì´í„°
        """
        if not RAG_AVAILABLE:
            logger.warning("âš ï¸  RAG ëª¨ë“ˆ ì—†ìŒ - ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©")
            return self._load_prompt_from_dynamodb(engine_type)

        try:
            logger.info("ğŸ” RAG ëª¨ë“œ: ë²¡í„° ê²€ìƒ‰ ì‹œì‘")

            # 1. ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰
            vector_search = get_vector_search()
            relevant_chunks = vector_search.search_similar_chunks(
                query=user_message,
                top_k=int(os.environ.get('RAG_TOP_K', '10')),
                min_similarity=float(os.environ.get('RAG_MIN_SIMILARITY', '0.7'))
            )

            if not relevant_chunks:
                logger.warning("âš ï¸  RAG ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ - ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©")
                return self._load_prompt_from_dynamodb(engine_type)

            # 2. ê²€ìƒ‰ ê²°ê³¼ë¡œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            max_rag_tokens = int(os.environ.get('RAG_MAX_TOKENS', '15000'))
            rag_context = vector_search.build_context_from_results(
                relevant_chunks,
                max_tokens=max_rag_tokens
            )

            # 3. ê¸°ë³¸ instructionê³¼ descriptionì€ ìœ ì§€ (ì½”ì–´ ì§€ì¹¨)
            base_prompt = self._load_prompt_from_dynamodb(engine_type)

            # 4. RAG ê°•í™” í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            rag_prompt_data = {
                'instruction': base_prompt.get('instruction', ''),
                'description': base_prompt.get('description', ''),
                'files': [
                    {
                        'fileName': 'rag_retrieved_context.txt',
                        'fileContent': rag_context,
                        'fileType': 'text'
                    }
                ]
            }

            logger.info(f"âœ… RAG í”„ë¡¬í”„íŠ¸ êµ¬ì„± ì™„ë£Œ: {len(relevant_chunks)}ê°œ ì²­í¬")
            logger.info(f"   - Instruction: {len(rag_prompt_data['instruction'])} chars")
            logger.info(f"   - Description: {len(rag_prompt_data['description'])} chars")
            logger.info(f"   - RAG Context: ~{max_rag_tokens} tokens")

            return rag_prompt_data

        except Exception as e:
            logger.error(f"âŒ RAG í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            logger.info("ğŸ”„ Fallback: ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©")
            return self._load_prompt_from_dynamodb(engine_type)
    
    def stream_response(
        self,
        user_message: str,
        engine_type: str,
        conversation_id: str,
        user_id: str,
        conversation_history: List[Dict],
        user_role: str = 'user'
    ) -> Generator[str, None, None]:
        """
        Bedrock ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±

        Yields:
            str: ì‘ë‹µ ì²­í¬
        """
        try:
            # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
            formatted_history = self._format_conversation_for_bedrock(conversation_history)

            # RAG ì‚¬ìš© ì—¬ë¶€ ê²°ì • (í™˜ê²½ë³€ìˆ˜ë¡œ ì œì–´)
            use_rag = os.environ.get('USE_RAG', 'false').lower() == 'true'

            if use_rag and RAG_AVAILABLE:
                # RAG ë°©ì‹: ë™ì  í”„ë¡¬í”„íŠ¸ êµ¬ì„±
                logger.info("ğŸ“š RAG ëª¨ë“œ í™œì„±í™”")
                prompt_data = self._create_rag_enhanced_prompt(
                    user_message=user_message,
                    engine_type=engine_type
                )
            else:
                # ê¸°ì¡´ ë°©ì‹: ì „ì²´ í”„ë¡¬í”„íŠ¸ ìºì‹±
                logger.info("ğŸ’¾ ìºì‹œ ëª¨ë“œ í™œì„±í™”")
                prompt_data = self._load_prompt_from_dynamodb(engine_type)

            logger.info(f"Loaded prompt for {engine_type}: instruction={len(prompt_data.get('instruction', ''))} chars")
            logger.info(f"Streaming response for engine {engine_type}")
            logger.info(f"Conversation context: {len(formatted_history)} messages")
            
            # AI ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ (Anthropic ë˜ëŠ” Bedrock)
            total_response = ""
            
            # ì›¹ ê²€ìƒ‰ í™œì„±í™” ì—¬ë¶€ í™•ì¸
            enable_web_search = os.environ.get('ENABLE_NATIVE_WEB_SEARCH', 'true').lower() == 'true'
            
            # Anthropic API ì‚¬ìš© ì‹œ
            if self.ai_provider == 'anthropic' and hasattr(self.ai_client, 'stream_response'):
                try:
                    logger.info(f"Using Anthropic API for {engine_type} (web_search: {enable_web_search})")
                    
                    # í”„ë¡¬í”„íŠ¸ì™€ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê²°í•©
                    full_system_prompt = self._build_system_prompt(
                        guidelines=prompt_data.get('instruction', ''),
                        description=prompt_data.get('description', ''),
                        files=prompt_data.get('files', []),
                        conversation_context=formatted_history
                    )
                    
                    for chunk in self.ai_client.stream_response(
                        user_message=user_message,
                        system_prompt=full_system_prompt,
                        conversation_context=formatted_history,
                        enable_web_search=enable_web_search,
                        enable_caching=True  # í”„ë¡¬í”„íŠ¸ ìºì‹± í™œì„±í™”
                    ):
                        total_response += chunk
                        yield chunk
                        
                except Exception as e:
                    # Anthropic API ì‹¤íŒ¨ ì‹œ Bedrockìœ¼ë¡œ í´ë°±
                    if os.environ.get('FALLBACK_TO_BEDROCK', 'true').lower() == 'true':
                        logger.warning(f"Anthropic API failed, falling back to Bedrock: {str(e)}")
                        total_response = ""
                        for chunk in self.bedrock_client.stream_bedrock(
                            user_message=user_message,
                            engine_type=engine_type,
                            conversation_context=formatted_history,
                            user_role=user_role,
                            guidelines=prompt_data.get('instruction'),
                            description=prompt_data.get('description'),
                            files=prompt_data.get('files', [])
                        ):
                            total_response += chunk
                            yield chunk
                    else:
                        raise
            
            # Bedrock ì‚¬ìš© ì‹œ (ê¸°ì¡´ ë¡œì§)
            else:
                for chunk in self.bedrock_client.stream_bedrock(
                    user_message=user_message,
                    engine_type=engine_type,
                    conversation_context=formatted_history,  # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬
                    user_role=user_role,
                    guidelines=prompt_data.get('instruction'),  # DynamoDB instruction ì „ë‹¬
                    description=prompt_data.get('description'),  # DynamoDB description ì „ë‹¬
                    files=prompt_data.get('files', [])  # DynamoDB files ì „ë‹¬
                ):
                    total_response += chunk
                    yield chunk
            
            # ì›¹ ê²€ìƒ‰ ì¶œì²˜ í¬ë§·íŒ… ì ìš© (Anthropic API ì‚¬ìš© ì‹œ)
            if total_response and self.ai_provider == 'anthropic' and enable_web_search:
                # ì¶œì²˜ê°€ ìë™ìœ¼ë¡œ í¬í•¨ë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ í¬ë§·íŒ… ì ìš©
                if "ğŸ“š ì¶œì²˜:" not in total_response and "http" in total_response:
                    formatted_response = self.citation_formatter.format_response_with_citations(total_response)
                    total_response = formatted_response
                    logger.info("Citation formatting applied")
            
            # AI ì‘ë‹µì„ ëŒ€í™”ì— ì €ì¥
            if total_response:
                self.conversation_manager.save_message(
                    conversation_id=conversation_id,
                    role='assistant',
                    content=total_response,
                    engine_type=engine_type,
                    user_id=user_id
                )
                logger.info(f"AI response saved: {len(total_response)} chars")
            
        except Exception as e:
            logger.error(f"Error streaming response: {str(e)}")
            raise
    
    def clear_history(self, conversation_id: str) -> bool:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"""
        try:
            # ìƒˆë¡œìš´ ëŒ€í™”ë¡œ ì¬ìƒì„±
            self.conversation_manager.create_or_update_conversation(
                conversation_id=conversation_id,
                title="Cleared conversation"
            )
            logger.info(f"Cleared history for conversation {conversation_id}")
            return True
        except Exception as e:
            logger.error(f"Error clearing history: {str(e)}")
            return False
    
    def track_usage(
        self,
        user_id: str,
        engine_type: str,
        input_text: str,
        output_text: str
    ) -> None:
        """ì‚¬ìš©ëŸ‰ ì¶”ì """
        try:
            # í† í° ê³„ì‚° (ê°„ë‹¨í•œ ì¶”ì •)
            input_tokens = int(len(input_text.split()) * 1.3)
            output_tokens = int(len(output_text.split()) * 1.3)
            total_tokens = input_tokens + output_tokens

            # í˜„ì¬ ë…„ì›” (YYYY-MM)
            now = datetime.now()
            year_month = now.strftime('%Y-%m')

            # DynamoDB í‚¤ (ì‹¤ì œ í…Œì´ë¸” êµ¬ì¡°ì— ë§ì¶¤)
            pk = f"user#{user_id}"
            sk = f"engine#{engine_type}#{year_month}"

            # ì—…ë°ì´íŠ¸
            self.usage_table.update_item(
                Key={
                    'PK': pk,
                    'SK': sk
                },
                UpdateExpression="""
                    SET messageCount = if_not_exists(messageCount, :zero) + :one,
                        inputTokens = if_not_exists(inputTokens, :zero) + :input,
                        outputTokens = if_not_exists(outputTokens, :zero) + :output,
                        totalTokens = if_not_exists(totalTokens, :zero) + :total,
                        engineType = :engine,
                        userId = :userId,
                        yearMonth = :yearMonth,
                        updatedAt = :now,
                        lastUsedAt = :now
                """,
                ExpressionAttributeValues={
                    ':zero': 0,
                    ':one': 1,
                    ':input': input_tokens,
                    ':output': output_tokens,
                    ':total': total_tokens,
                    ':engine': engine_type,
                    ':userId': user_id,
                    ':yearMonth': year_month,
                    ':now': now.isoformat()
                }
            )

            logger.info(f"Usage tracked: {user_id}, {engine_type}, "
                       f"tokens={input_tokens}+{output_tokens}")

        except Exception as e:
            logger.error(f"Error tracking usage: {str(e)}", exc_info=True)
    
    def _merge_conversation_history(
        self,
        client_history: List[Dict],
        db_history: List[Dict]
    ) -> List[Dict]:
        """
        í´ë¼ì´ì–¸íŠ¸ì™€ DBì˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ ë³‘í•©
        
        DB íˆìŠ¤í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•˜ë˜, í´ë¼ì´ì–¸íŠ¸ íˆìŠ¤í† ë¦¬ì—ë§Œ ìˆëŠ” ë©”ì‹œì§€ëŠ” ì¶”ê°€
        """
        merged = []
        
        # DB íˆìŠ¤í† ë¦¬ë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©
        for msg in db_history:
            merged.append({
                'role': msg.get('role', msg.get('type', 'user')),
                'content': msg.get('content', ''),
                'timestamp': msg.get('timestamp', '')
            })
        
        # í´ë¼ì´ì–¸íŠ¸ íˆìŠ¤í† ë¦¬ì—ë§Œ ìˆëŠ” ë©”ì‹œì§€ í™•ì¸ ë° ì¶”ê°€
        db_timestamps = {msg.get('timestamp') for msg in db_history if msg.get('timestamp')}
        
        for msg in client_history:
            timestamp = msg.get('timestamp')
            # íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ì—†ê±°ë‚˜ DBì— ì—†ëŠ” ë©”ì‹œì§€ëŠ” ìƒˆë¡œìš´ ë©”ì‹œì§€ë¡œ ê°„ì£¼
            if not timestamp or timestamp not in db_timestamps:
                # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ìµœê·¼ ë©”ì‹œì§€ì™€ ë¹„êµ
                content = msg.get('content', '')
                if not merged or merged[-1].get('content') != content:
                    merged.append({
                        'role': msg.get('role', 'user'),
                        'content': content,
                        'timestamp': timestamp or datetime.utcnow().isoformat() + 'Z'
                    })
        
        # ìµœëŒ€ 30ê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€ (ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ê´€ë¦¬) #ëŒ€í™”ê¸°ì–µê¸°ëŠ¥
        if len(merged) > 30:
            merged = merged[-30:]
        
        return merged
    
    def _build_system_prompt(
        self,
        guidelines: str,
        description: str,
        files: List[Dict],
        conversation_context: str
    ) -> str:
        """
        Anthropic APIìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        """
        prompt_parts = []
        
        # ê¸°ë³¸ ê°€ì´ë“œë¼ì¸
        if guidelines:
            prompt_parts.append(guidelines)
        
        # ì„¤ëª… ì¶”ê°€
        if description:
            prompt_parts.append(f"\n\n=== ì¶”ê°€ ì„¤ëª… ===\n{description}")
        
        # íŒŒì¼ ë‚´ìš© ì¶”ê°€
        if files:
            prompt_parts.append("\n\n=== ì°¸ê³  ë¬¸ì„œ ===")
            for file in files:
                file_name = file.get('fileName', 'Unknown')
                file_content = file.get('fileContent', '')
                if file_content:
                    prompt_parts.append(f"\n[{file_name}]\n{file_content}")
        
        # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        if conversation_context:
            prompt_parts.append(f"\n\n{conversation_context}")
        
        return "\n".join(prompt_parts)
    
    def _format_conversation_for_bedrock(self, conversation_history: List[Dict]) -> str:
        """
        Bedrockì— ì „ë‹¬í•  ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…
        """
        if not conversation_history:
            return ""
        
        formatted_messages = []
        for msg in conversation_history[-10:]:  # ìµœê·¼ 10ê°œ ë©”ì‹œì§€ë§Œ ì‚¬ìš© #ëŒ€í™”ê¸°ì–µê¸°ëŠ¥
            role = msg.get('role', 'user')
            content = msg.get('content', '')
            
            if content:
                if role == 'user':
                    formatted_messages.append(f"ì‚¬ìš©ì: {content}")
                elif role == 'assistant':
                    formatted_messages.append(f"AI: {content}")
        
        if formatted_messages:
            return "\n\n=== ì´ì „ ëŒ€í™” ë‚´ìš© ===\n" + "\n\n".join(formatted_messages) + "\n\n=== í˜„ì¬ ì§ˆë¬¸ ==="
        
        return ""