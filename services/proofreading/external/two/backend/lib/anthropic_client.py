"""
Anthropic API ì§ì ‘ í˜¸ì¶œ í´ë¼ì´ì–¸íŠ¸ - Prompt Caching ìµœì í™” ë²„ì „
AWS Bedrock ëŒ€ì‹  Anthropic APIë¥¼ ì§ì ‘ ì‚¬ìš©
ë¹„ìš© ìµœì í™”ë¥¼ ìœ„í•œ Prompt Caching ì ìš©
"""
import os
import json
import logging
import urllib.request
import urllib.parse
import urllib.error
import boto3
import uuid
from datetime import datetime, timezone, timedelta
from typing import Dict, Any, Iterator, Optional

logger = logging.getLogger(__name__)

# Secrets Manager í´ë¼ì´ì–¸íŠ¸
secrets_client = boto3.client('secretsmanager', region_name='us-east-1')

def get_api_key_from_secrets():
    """Secrets Managerì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°"""
    try:
        secret_name = os.environ.get('ANTHROPIC_SECRET_NAME', 'foreign-v1')
        response = secrets_client.get_secret_value(SecretId=secret_name)
        secret = json.loads(response['SecretString'])
        return secret.get('api_key', '')
    except Exception as e:
        logger.error(f"Failed to retrieve API key from Secrets Manager: {str(e)}")
        # í´ë°±: í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        return os.environ.get('ANTHROPIC_API_KEY', '')

# Anthropic API ì„¤ì •
ANTHROPIC_API_KEY = None  # ìš”ì²­ ì‹œì ì— ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜´
ANTHROPIC_API_URL = "https://api.anthropic.com/v1/messages"
ANTHROPIC_VERSION = "2023-06-01"

# ëª¨ë¸ ì„¤ì •
MODEL_ID = os.environ.get('ANTHROPIC_MODEL_ID', "claude-opus-4-5-20251101")  # Claude 4.5 Opus
MAX_TOKENS = int(os.environ.get('MAX_TOKENS', '4096'))
TEMPERATURE = float(os.environ.get('TEMPERATURE', '0.3'))

# ì›¹ ê²€ìƒ‰ ì„¤ì •
ENABLE_NATIVE_WEB_SEARCH = os.environ.get('ENABLE_NATIVE_WEB_SEARCH', 'true').lower() == 'true'
WEB_SEARCH_MAX_USES = int(os.environ.get('WEB_SEARCH_MAX_USES', '5'))

# ìºì‹± ì„¤ì •
CACHE_TTL = os.environ.get('PROMPT_CACHE_TTL', '1h')  # 1ì‹œê°„ ìºì‹œ

def _replace_template_variables(prompt: str) -> str:
    """
    ì •ì  í…œí”Œë¦¿ ë³€ìˆ˜ë§Œ ì¹˜í™˜ (ìºì‹± ìµœì í™”)
    ë™ì  ë³€ìˆ˜ëŠ” user_messageì— ì¶”ê°€í•˜ì—¬ ìºì‹œ ë¬´íš¨í™” ë°©ì§€
    """
    replacements = {
        '{{user_location}}': 'ëŒ€í•œë¯¼êµ­',
        '{{timezone}}': 'Asia/Seoul (KST)',
        '{{language}}': 'í•œêµ­ì–´',
        '{{service_name}}': 'êµì—´ ì„œë¹„ìŠ¤'
    }
    
    for key, value in replacements.items():
        prompt = prompt.replace(key, value)
    
    return prompt

def _create_dynamic_context() -> str:
    """
    ë™ì  ì»¨í…ìŠ¤íŠ¸ ìƒì„± (user_messageì— ì¶”ê°€ìš©)
    ìºì‹œ ë¬´íš¨í™”ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ system promptê°€ ì•„ë‹Œ user messageì— í¬í•¨
    """
    kst = timezone(timedelta(hours=9))
    current_time = datetime.now(kst)
    session_id = str(uuid.uuid4())[:8]
    
    return f"""[í˜„ì¬ ì„¸ì…˜ ì •ë³´]
- í˜„ì¬ ì‹œê°„: {current_time.strftime('%Y-%m-%d %H:%M:%S KST')}
- ì˜¤ëŠ˜ ë‚ ì§œ: {current_time.strftime('%Yë…„ %mì›” %dì¼')}
- ì„¸ì…˜ ID: {session_id}
- ì—°ë„ ê¸°ì¤€: {current_time.year}ë…„"""

def stream_anthropic_response(
    user_message: str,
    system_prompt: str,
    api_key: Optional[str] = None,
    enable_web_search: bool = False,
    web_search_max_uses: int = 5,
    use_caching: bool = True
) -> Iterator[Dict[str, Any]]:
    """
    Anthropic APIë¥¼ í†µí•œ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± (Prompt Caching ì ìš©)
    
    Args:
        user_message: ì‚¬ìš©ì ë©”ì‹œì§€
        system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        api_key: API í‚¤ (ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)
        enable_web_search: ì›¹ ê²€ìƒ‰ ë„êµ¬ í™œì„±í™” ì—¬ë¶€
        web_search_max_uses: ì›¹ ê²€ìƒ‰ ìµœëŒ€ ì‚¬ìš© íšŸìˆ˜
        use_caching: í”„ë¡¬í”„íŠ¸ ìºì‹± ì‚¬ìš© ì—¬ë¶€
    
    Yields:
        ì‘ë‹µ ë”•ì…”ë„ˆë¦¬ (í…ìŠ¤íŠ¸ ì²­í¬, ì‚¬ìš©ëŸ‰ ì •ë³´ ë“±)
    """
    try:
        # API í‚¤ í™•ì¸ (Secrets Managerì—ì„œ ê°€ì ¸ì˜¤ê¸°)
        api_key = api_key or get_api_key_from_secrets()
        if not api_key:
            logger.error("Anthropic API key not found")
            yield {"error": "API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
            return
        
        # ìš”ì²­ í—¤ë”
        headers = {
            "x-api-key": api_key,
            "anthropic-version": ANTHROPIC_VERSION,
            "anthropic-beta": "prompt-caching-2024-07-31",  # Prompt Caching ë² íƒ€ í—¤ë”
            "content-type": "application/json",
            "accept": "text/event-stream"
        }
        
        # ì •ì  ë³€ìˆ˜ ì¹˜í™˜ (ìºì‹œ ê°€ëŠ¥í•˜ë„ë¡)
        static_system_prompt = _replace_template_variables(system_prompt)
        
        # ë™ì  ì»¨í…ìŠ¤íŠ¸ë¥¼ user messageì— ì¶”ê°€
        dynamic_context = _create_dynamic_context()
        enhanced_user_message = f"{dynamic_context}\n\n{user_message}"
        
        # ìš”ì²­ ë³¸ë¬¸ (Prompt Caching ì ìš©)
        body = {
            "model": MODEL_ID,
            "max_tokens": MAX_TOKENS,
            "temperature": TEMPERATURE,
            "messages": [
                {"role": "user", "content": enhanced_user_message}
            ],
            "stream": True
        }
        
        # Prompt Caching ì ìš© (system promptë§Œ ìºì‹±)
        if use_caching:
            body["system"] = [
                {
                    "type": "text",
                    "text": static_system_prompt,
                    "cache_control": {"type": "ephemeral", "ttl": CACHE_TTL}  # 1ì‹œê°„ ìºì‹œ
                }
            ]
            logger.info(f"âœ… Prompt caching enabled (TTL: {CACHE_TTL})")
        else:
            body["system"] = static_system_prompt
        
        # ì›¹ ê²€ìƒ‰ ë„êµ¬ ì¶”ê°€
        if enable_web_search and ENABLE_NATIVE_WEB_SEARCH:
            body["tools"] = [
                {
                    "type": "web_search_20250305",
                    "name": "web_search",
                    "max_uses": web_search_max_uses
                }
            ]
            logger.info(f"Web search enabled (max uses: {web_search_max_uses})")
        
        logger.info(f"Calling Anthropic API with model: {MODEL_ID}, caching: {use_caching}")
        
        # API í˜¸ì¶œ (ìŠ¤íŠ¸ë¦¬ë°)
        data = json.dumps(body).encode('utf-8')
        request = urllib.request.Request(
            ANTHROPIC_API_URL,
            data=data,
            headers=headers,
            method='POST'
        )
        response = urllib.request.urlopen(request)
        
        if response.status != 200:
            error_msg = f"API ì˜¤ë¥˜: {response.status} - {response.reason}"
            logger.error(error_msg)
            yield {"error": error_msg}
            return
        
        # ì‚¬ìš©ëŸ‰ ì¶”ì ì„ ìœ„í•œ ë³€ìˆ˜
        usage_info = {
            'input_tokens': 0,
            'output_tokens': 0,
            'cache_read_input_tokens': 0,
            'cache_creation_input_tokens': 0
        }
        
        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
        for line in response:
            if line:
                line_text = line.decode('utf-8').strip()
                
                # SSE í˜•ì‹ íŒŒì‹±
                if line_text.startswith('data: '):
                    data_str = line_text[6:]  # 'data: ' ì œê±°
                    
                    if data_str == '[DONE]':
                        logger.info("Streaming completed")
                        # ìµœì¢… ì‚¬ìš©ëŸ‰ ì •ë³´ ë°˜í™˜
                        yield {"usage": usage_info}
                        break
                    
                    try:
                        data = json.loads(data_str)
                        
                        # ë©”ì‹œì§€ ì‹œì‘ ì´ë²¤íŠ¸ (ì‚¬ìš©ëŸ‰ ì •ë³´ í¬í•¨)
                        if data.get('type') == 'message_start':
                            message = data.get('message', {})
                            usage = message.get('usage', {})
                            usage_info.update({
                                'input_tokens': usage.get('input_tokens', 0),
                                'cache_read_input_tokens': usage.get('cache_read_input_tokens', 0),
                                'cache_creation_input_tokens': usage.get('cache_creation_input_tokens', 0)
                            })
                            
                            # ìºì‹œ íˆíŠ¸/ë¯¸ìŠ¤ ë¡œê¹…
                            if usage_info['cache_read_input_tokens'] > 0:
                                logger.info(f"ğŸ¯ Cache HIT! Read {usage_info['cache_read_input_tokens']} tokens from cache")
                            if usage_info['cache_creation_input_tokens'] > 0:
                                logger.info(f"ğŸ’¾ Cache MISS! Created cache with {usage_info['cache_creation_input_tokens']} tokens")
                        
                        # ì»¨í…ì¸  ë¸”ë¡ ë¸íƒ€ ì²˜ë¦¬
                        elif data.get('type') == 'content_block_delta':
                            delta = data.get('delta', {})
                            if delta.get('type') == 'text_delta':
                                text = delta.get('text', '')
                                if text:
                                    yield {"text": text}
                        
                        # ë©”ì‹œì§€ ë¸íƒ€ (ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸)
                        elif data.get('type') == 'message_delta':
                            delta = data.get('delta', {})
                            usage = delta.get('usage', {})
                            if usage.get('output_tokens'):
                                usage_info['output_tokens'] = usage.get('output_tokens', 0)
                        
                        # ì—ëŸ¬ ì²˜ë¦¬
                        elif data.get('type') == 'error':
                            error = data.get('error', {})
                            error_msg = error.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')
                            logger.error(f"API Error: {error_msg}")
                            yield {"error": error_msg}
                            break
                    
                    except json.JSONDecodeError as e:
                        logger.warning(f"Failed to parse SSE data: {e}")
                        continue
    
    except urllib.error.URLError as e:
        logger.error(f"Request error: {str(e)}")
        yield {"error": f"ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {str(e)}"}
    
    except Exception as e:
        logger.error(f"Unexpected error: {str(e)}")
        yield {"error": f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}"}


class AnthropicClient:
    """Anthropic API ì§ì ‘ í˜¸ì¶œ í´ë¼ì´ì–¸íŠ¸ (Prompt Caching ìµœì í™”)"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        Args:
            api_key: Anthropic API í‚¤ (ì—†ìœ¼ë©´ Secrets Managerì—ì„œ ê°€ì ¸ì˜´)
        """
        self.api_key = api_key or get_api_key_from_secrets()
        if not self.api_key:
            logger.warning("Anthropic API key not set")
        
        self.model_id = MODEL_ID
        self.max_tokens = MAX_TOKENS
        self.temperature = TEMPERATURE
        self.last_usage = {}  # ë§ˆì§€ë§‰ ì‚¬ìš©ëŸ‰ ì •ë³´ ì €ì¥
        
        logger.info("AnthropicClient initialized with prompt caching support")
    
    def _calculate_cost(self, usage: Dict[str, int]) -> float:
        """
        ë¹„ìš© ê³„ì‚° (Claude Opus 4.5 ê¸°ì¤€)
        
        Pricing (per 1M tokens):
        - Base Input: $5.00
        - Output: $25.00
        - Cache Write (1h): $10.00
        - Cache Read: $0.50
        """
        PRICE_INPUT = 5.0  # Base Input Tokens
        PRICE_OUTPUT = 25.0  # Output Tokens
        PRICE_CACHE_WRITE = 10.0  # 1h Cache Writes
        PRICE_CACHE_READ = 0.50  # Cache Hits
        
        cost_input = (usage.get('input_tokens', 0) / 1_000_000) * PRICE_INPUT
        cost_output = (usage.get('output_tokens', 0) / 1_000_000) * PRICE_OUTPUT
        cost_cache_write = (usage.get('cache_creation_input_tokens', 0) / 1_000_000) * PRICE_CACHE_WRITE
        cost_cache_read = (usage.get('cache_read_input_tokens', 0) / 1_000_000) * PRICE_CACHE_READ
        
        total_cost = cost_input + cost_output + cost_cache_write + cost_cache_read
        
        # ìƒì„¸ ë¹„ìš© ë¡œê¹…
        logger.info(f"ğŸ’° Cost Breakdown:")
        logger.info(f"  - Input: ${cost_input:.6f} ({usage.get('input_tokens', 0)} tokens)")
        logger.info(f"  - Output: ${cost_output:.6f} ({usage.get('output_tokens', 0)} tokens)")
        logger.info(f"  - Cache Write: ${cost_cache_write:.6f} ({usage.get('cache_creation_input_tokens', 0)} tokens)")
        logger.info(f"  - Cache Read: ${cost_cache_read:.6f} ({usage.get('cache_read_input_tokens', 0)} tokens)")
        logger.info(f"  - TOTAL: ${total_cost:.6f}")
        
        return total_cost
    
    def stream_response(
        self,
        user_message: str,
        system_prompt: str,
        conversation_context: str = "",
        enable_web_search: bool = False,
        web_search_max_uses: int = 5,
        use_caching: bool = True
    ) -> Iterator[str]:
        """
        ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± (Prompt Caching ì ìš©)
        
        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            conversation_context: ëŒ€í™” ì»¨í…ìŠ¤íŠ¸
            enable_web_search: ì›¹ ê²€ìƒ‰ í™œì„±í™” ì—¬ë¶€
            web_search_max_uses: ì›¹ ê²€ìƒ‰ ìµœëŒ€ ì‚¬ìš© íšŸìˆ˜
            use_caching: í”„ë¡¬í”„íŠ¸ ìºì‹± ì‚¬ìš© ì—¬ë¶€
        
        Yields:
            ì‘ë‹µ ì²­í¬
        """
        try:
            # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ í¬í•¨
            if conversation_context:
                full_prompt = f"{conversation_context}\n\n{system_prompt}"
            else:
                full_prompt = system_prompt
            
            logger.info(f"Streaming with Anthropic API (web_search: {enable_web_search}, caching: {use_caching})")
            
            # ì‚¬ìš©ëŸ‰ ì¶”ì  ì´ˆê¸°í™”
            self.last_usage = {
                'input_tokens': 0,
                'output_tokens': 0,
                'cache_read_input_tokens': 0,
                'cache_creation_input_tokens': 0
            }
            
            # Anthropic API ìŠ¤íŠ¸ë¦¬ë° (Prompt Caching í¬í•¨)
            for chunk in stream_anthropic_response(
                user_message=user_message,
                system_prompt=full_prompt,
                api_key=self.api_key,
                enable_web_search=enable_web_search,
                web_search_max_uses=web_search_max_uses,
                use_caching=use_caching
            ):
                if "text" in chunk:
                    yield chunk["text"]
                elif "usage" in chunk:
                    # ì‚¬ìš©ëŸ‰ ì •ë³´ ì—…ë°ì´íŠ¸
                    self.last_usage.update(chunk["usage"])
                    
                    # ë¹„ìš© ê³„ì‚°
                    cost = self._calculate_cost(self.last_usage)
                    self.last_usage['total_cost'] = cost
                    
                    # ìºì‹œ íš¨ìœ¨ì„± ê³„ì‚°
                    total_input = self.last_usage['input_tokens'] + self.last_usage['cache_creation_input_tokens']
                    if total_input > 0:
                        cache_efficiency = (self.last_usage['cache_read_input_tokens'] / total_input) * 100
                        logger.info(f"ğŸ“Š Cache Efficiency: {cache_efficiency:.1f}%")
                
                elif "error" in chunk:
                    yield f"\n\n[ì˜¤ë¥˜] {chunk['error']}"
        
        except Exception as e:
            logger.error(f"Error in stream_response: {str(e)}")
            yield f"\n\n[ì˜¤ë¥˜] ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}"
    
    def get_last_usage(self) -> Dict[str, Any]:
        """ë§ˆì§€ë§‰ ìš”ì²­ì˜ ì‚¬ìš©ëŸ‰ ì •ë³´ ë°˜í™˜"""
        return self.last_usage