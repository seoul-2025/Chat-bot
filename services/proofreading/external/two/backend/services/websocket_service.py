"""
WebSocket ì„œë¹„ìŠ¤ - ì™„ì„± ë²„ì „ (Permanent Prompt Caching ì ìš©)
ìš°ìˆ˜ì‚¬ë¡€ ì½”ë“œë¥¼ ì°¸ê³ í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ê¸°ëŠ¥ ì¶”ê°€
ì˜êµ¬ ì¸ë©”ëª¨ë¦¬ ìºì‹±ìœ¼ë¡œ DynamoDB ì¡°íšŒ ìµœì†Œí™” (Lambda ì»¨í…Œì´ë„ˆ ìˆ˜ëª… ë™ì•ˆ ìœ ì§€)
"""
import os
import sys
import json
import boto3
import logging
import time
from typing import Dict, List, Generator, Optional, Any
from datetime import datetime, timezone
from decimal import Decimal

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from src.config.aws import AWS_REGION, DYNAMODB_TABLES
from lib.bedrock_client_enhanced import BedrockClientEnhanced, create_enhanced_system_prompt
from lib.anthropic_client import AnthropicClient
from utils.logger import setup_logger

logger = setup_logger(__name__)

# ê¸€ë¡œë²Œ ìºì‹œ - Lambda ì»¨í…Œì´ë„ˆ ì¬ì‚¬ìš© ì‹œ ì˜êµ¬ ìœ ì§€ (TTL ì œê±°)
PROMPT_CACHE: Dict[str, Dict[str, Any]] = {}
# CACHE_TTL ì œê±° - ì˜êµ¬ ìºì‹œë¡œ ì „í™˜

class WebSocketService:
    """WebSocket í†µì‹  ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        # AWS ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™”
        self.dynamodb = boto3.resource('dynamodb', region_name=AWS_REGION)
        self.conversations_table = self.dynamodb.Table(DYNAMODB_TABLES['conversations'])
        self.prompts_table = self.dynamodb.Table(DYNAMODB_TABLES['prompts'])
        self.usage_table = self.dynamodb.Table(DYNAMODB_TABLES['usage'])
        self.daily_usage_table = self.dynamodb.Table(DYNAMODB_TABLES['daily_usage'])  # ì¼ë³„ ì‚¬ìš©ëŸ‰ ì¶”ì 
        self.files_table = self.dynamodb.Table(DYNAMODB_TABLES['files'])  # íŒŒì¼ í…Œì´ë¸” ì¶”ê°€

        # AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (í™˜ê²½ë³€ìˆ˜ì— ë”°ë¼ ì„ íƒ)
        use_anthropic = os.environ.get('USE_ANTHROPIC_API', 'false').lower() == 'true'
        if use_anthropic:
            self.ai_client = AnthropicClient()
            self.ai_provider = 'anthropic'
            logger.info("Using Anthropic API (Claude 4.5 Opus)")
        else:
            self.ai_client = BedrockClientEnhanced()
            self.ai_provider = 'bedrock'
            logger.info("Using AWS Bedrock (Claude 3.5 Sonnet)")
        
        # Bedrock í´ë¼ì´ì–¸íŠ¸ë„ í´ë°±ìš©ìœ¼ë¡œ ìœ ì§€
        self.bedrock_client = BedrockClientEnhanced()

        # ëŒ€í™” ê´€ë¦¬ì
        from handlers.websocket.conversation_manager import ConversationManager
        self.conversation_manager = ConversationManager()

        logger.info("WebSocketService initialized")
    
    def _load_prompt_from_dynamodb(self, engine_type: str) -> Dict[str, Any]:
        """
        DynamoDBì—ì„œ í”„ë¡¬í”„íŠ¸ì™€ íŒŒì¼ ë¡œë“œ (ì˜êµ¬ ì¸ë©”ëª¨ë¦¬ ìºì‹± ì ìš©)

        ìºì‹œ íˆíŠ¸ ì‹œ DB ì¡°íšŒë¥¼ ì™„ì „íˆ ìƒëµí•˜ì—¬ ìµœëŒ€ ì„±ëŠ¥ í–¥ìƒ
        Lambda ì»¨í…Œì´ë„ˆê°€ ì¬ì‹œì‘ë  ë•Œê¹Œì§€ ìºì‹œ ìœ ì§€
        """
        global PROMPT_CACHE

        # ì˜êµ¬ ìºì‹œ í™•ì¸ (TTL ì—†ìŒ)
        if engine_type in PROMPT_CACHE:
            logger.info(f"âœ… Cache HIT for {engine_type} - DB query skipped (permanent cache)")
            return PROMPT_CACHE[engine_type]

        logger.info(f"âŒ Cache MISS for {engine_type} - fetching from DB (first time)")

        # ìºì‹œ ë¯¸ìŠ¤ - DBì—ì„œ ë¡œë“œ
        prompt_data = self._fetch_prompt_from_db(engine_type)

        # ì˜êµ¬ ìºì‹œ ì—…ë°ì´íŠ¸
        PROMPT_CACHE[engine_type] = prompt_data
        logger.info(f"ğŸ’¾ Permanently cached prompt for {engine_type} "
                   f"({len(prompt_data.get('files', []))} files, "
                   f"{len(str(prompt_data))} bytes)")

        return prompt_data

    def _fetch_prompt_from_db(self, engine_type: str) -> Dict[str, Any]:
        """
        ì‹¤ì œ DB ì¡°íšŒ ë¡œì§ (ìºì‹± ì „ìš©)
        ìºì‹œ ë¯¸ìŠ¤ ì‹œì—ë§Œ í˜¸ì¶œë¨
        """
        try:
            start_time = time.time()

            # í”„ë¡¬í”„íŠ¸ í…Œì´ë¸”ì—ì„œ ê¸°ë³¸ ì •ë³´ ë¡œë“œ (id í‚¤ ì‚¬ìš©)
            response = self.prompts_table.get_item(Key={'id': engine_type})
            if 'Item' in response:
                item = response['Item']
                prompt_data = {
                    'instruction': item.get('instruction', ''),
                    'description': item.get('description', ''),
                    'files': []
                }

                # files í…Œì´ë¸”ì—ì„œ ê´€ë ¨ íŒŒì¼ë“¤ ë¡œë“œ
                try:
                    files_response = self.files_table.scan(
                        FilterExpression='promptId = :promptId',
                        ExpressionAttributeValues={':promptId': engine_type}
                    )

                    if 'Items' in files_response:
                        for file_item in files_response['Items']:
                            prompt_data['files'].append({
                                'fileName': file_item.get('fileName', ''),
                                'fileContent': file_item.get('fileContent', ''),
                                'fileType': 'text'  # ê¸°ë³¸ê°’
                            })
                except Exception as fe:
                    logger.error(f"Error loading files: {str(fe)}")

                elapsed = (time.time() - start_time) * 1000
                logger.info(f"ğŸ” DB fetch for {engine_type}: "
                          f"{len(prompt_data['files'])} files in {elapsed:.0f}ms")

                return prompt_data
            else:
                logger.warning(f"No prompt found for engine type: {engine_type}")
                return {'instruction': '', 'description': '', 'files': []}
        except Exception as e:
            logger.error(f"Error loading prompt from DynamoDB: {str(e)}")
            return {'instruction': '', 'description': '', 'files': []}

    
    def stream_response(
        self,
        user_message: str,
        engine_type: str,
        conversation_id: str,
        user_id: str,
        conversation_history: List[Dict],
        user_role: str = 'user'
    ) -> Generator[str, None, None]:
        """
        Bedrock ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
        
        Yields:
            str: ì‘ë‹µ ì²­í¬
        """
        try:
            # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
            formatted_history = self._format_conversation_for_bedrock(conversation_history)
            
            # DynamoDBì—ì„œ í”„ë¡¬í”„íŠ¸ì™€ íŒŒì¼ í†µí•© ë¡œë“œ
            prompt_data = self._load_prompt_from_dynamodb(engine_type)
            logger.info(f"Loaded prompt for {engine_type}: instruction={len(prompt_data.get('instruction', ''))} chars")

            logger.info(f"Streaming response for engine {engine_type}")
            logger.info(f"Conversation context: {len(formatted_history)} messages")

            # AI ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ (Anthropic ë˜ëŠ” Bedrock)
            total_response = ""
            
            # Anthropic API ì‚¬ìš© ì‹œ
            if self.ai_provider == 'anthropic' and hasattr(self.ai_client, 'stream_response'):
                try:
                    logger.info(f"Using Anthropic API for {engine_type} with prompt caching")
                    
                    # í”„ë¡¬í”„íŠ¸ì™€ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê²°í•© (Bedrockê³¼ ë™ì¼í•œ ì²´ê³„ì  í”„ë¡¬í”„íŠ¸)
                    full_system_prompt = self._build_system_prompt(
                        guidelines=prompt_data.get('instruction', ''),
                        description=prompt_data.get('description', ''),
                        files=prompt_data.get('files', []),
                        conversation_context=formatted_history,
                        engine_type=engine_type,
                        user_role=user_role
                    )
                    
                    # ì›¹ ê²€ìƒ‰ í™œì„±í™” ì—¬ë¶€ íŒë‹¨
                    enable_web_search = self._should_enable_web_search(user_message)
                    
                    # Prompt Caching í™œì„±í™” (ê¸°ë³¸ê°’: True)
                    use_caching = os.environ.get('ENABLE_PROMPT_CACHING', 'true').lower() == 'true'
                    
                    for chunk in self.ai_client.stream_response(
                        user_message=user_message,
                        system_prompt=full_system_prompt,
                        conversation_context=formatted_history,
                        enable_web_search=enable_web_search,
                        web_search_max_uses=int(os.environ.get('WEB_SEARCH_MAX_USES', '5')),
                        use_caching=use_caching  # Prompt Caching íŒŒë¼ë¯¸í„° ì¶”ê°€
                    ):
                        total_response += chunk
                        yield chunk
                        
                    # ì‚¬ìš©ëŸ‰ ì •ë³´ ë¡œê¹… (ë¹„ìš© í¬í•¨)
                    if hasattr(self.ai_client, 'get_last_usage'):
                        usage = self.ai_client.get_last_usage()
                        if usage:
                            logger.info(f"ğŸ“Š API Usage: {usage}")
                            if 'total_cost' in usage:
                                logger.info(f"ğŸ’µ Total cost for this request: ${usage['total_cost']:.6f}")
                        
                except Exception as e:
                    # Anthropic API ì‹¤íŒ¨ ì‹œ Bedrockìœ¼ë¡œ í´ë°±
                    if os.environ.get('FALLBACK_TO_BEDROCK', 'true').lower() == 'true':
                        logger.warning(f"Anthropic API failed, falling back to Bedrock: {str(e)}")
                        total_response = ""
                        for chunk in self.bedrock_client.stream_bedrock(
                            user_message=user_message,
                            engine_type=engine_type,
                            conversation_context=formatted_history,
                            user_role=user_role,
                            guidelines=prompt_data.get('instruction'),
                            description=prompt_data.get('description'),
                            files=prompt_data.get('files', [])
                        ):
                            total_response += chunk
                            yield chunk
                    else:
                        raise
            
            # Bedrock ì‚¬ìš© ì‹œ (ê¸°ì¡´ ë¡œì§)
            else:
                for chunk in self.bedrock_client.stream_bedrock(
                    user_message=user_message,
                    engine_type=engine_type,
                    conversation_context=formatted_history,  # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬
                    user_role=user_role,
                    guidelines=prompt_data.get('instruction'),  # DynamoDB instruction ì „ë‹¬
                    description=prompt_data.get('description'),  # DynamoDB description ì „ë‹¬
                    files=prompt_data.get('files', [])  # DynamoDB files ì „ë‹¬
                ):
                    total_response += chunk
                    yield chunk
            
            # AI ì‘ë‹µì„ ëŒ€í™”ì— ì €ì¥
            if total_response:
                self.conversation_manager.save_message(
                    conversation_id=conversation_id,
                    role='assistant',
                    content=total_response,
                    engine_type=engine_type,
                    user_id=user_id
                )
                logger.info(f"AI response saved: {len(total_response)} chars")
            
        except Exception as e:
            logger.error(f"Error streaming response: {str(e)}")
            yield f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def process_message(
        self,
        user_message: str,
        engine_type: str,
        conversation_id: Optional[str],
        user_id: str,
        conversation_history: List[Dict],
        user_role: str = 'user'
    ) -> Dict[str, Any]:
        """
        ë©”ì‹œì§€ ì²˜ë¦¬ ë° ëŒ€í™” íˆìŠ¤í† ë¦¬ ë³‘í•©

        Returns:
            Dict containing conversation_id and merged_history
        """
        try:
            # ëŒ€í™” IDê°€ ì—†ìœ¼ë©´ ìƒì„±
            if not conversation_id:
                import uuid
                conversation_id = str(uuid.uuid4())
                logger.info(f"New conversation created: {conversation_id}")

            # DBì—ì„œ ê¸°ì¡´ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ
            db_history = self.conversation_manager.get_conversation_history(
                conversation_id,
                limit=20  # ìµœê·¼ 20ê°œ ë©”ì‹œì§€
            )

            # í´ë¼ì´ì–¸íŠ¸ íˆìŠ¤í† ë¦¬ì™€ DB íˆìŠ¤í† ë¦¬ ë³‘í•©
            merged_history = self._merge_conversation_history(
                client_history=conversation_history,
                db_history=db_history
            )

            # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™”ì— ì €ì¥
            self.conversation_manager.save_message(
                conversation_id=conversation_id,
                role='user',
                content=user_message,
                engine_type=engine_type,
                user_id=user_id
            )

            # ë³‘í•©ëœ íˆìŠ¤í† ë¦¬ì— í˜„ì¬ ë©”ì‹œì§€ ì¶”ê°€
            merged_history.append({
                'role': 'user',
                'content': user_message,
                'timestamp': datetime.utcnow().isoformat() + 'Z'
            })

            logger.info(f"Processed message for conversation {conversation_id}")
            logger.info(f"Merged history length: {len(merged_history)}")

            return {
                'conversation_id': conversation_id,
                'merged_history': merged_history
            }

        except Exception as e:
            logger.error(f"Error processing message: {str(e)}")
            raise

    def process_conversation(
        self,
        user_message: str,
        conversation_id: str,
        user_id: str,
        conversation_history: List[Dict],
        user_role: str = 'user'
    ) -> Dict:
        """
        ëŒ€í™” ì²˜ë¦¬ ë° íˆìŠ¤í† ë¦¬ ë³‘í•©

        Returns:
            Dict: conversation_idì™€ ë³‘í•©ëœ íˆìŠ¤í† ë¦¬
        """
        try:
            # ëŒ€í™” ID ìƒì„± ë˜ëŠ” ê²€ì¦
            if not conversation_id:
                # ìƒˆ ëŒ€í™” ìƒì„±
                conversation_id = f"{user_id}_{datetime.now().timestamp()}"
                logger.info(f"Created new conversation: {conversation_id}")

            # DBì—ì„œ ê¸°ì¡´ ëŒ€í™” ë¡œë“œ
            db_history = []
            if conversation_id:
                try:
                    response = self.conversations_table.get_item(
                        Key={
                            'userId': user_id,
                            'conversationId': conversation_id
                        }
                    )
                    if 'Item' in response:
                        db_history = response['Item'].get('messages', [])
                        logger.info(f"Loaded {len(db_history)} messages from DB")
                except Exception as e:
                    logger.error(f"Error loading conversation from DB: {e}")

            # í´ë¼ì´ì–¸íŠ¸ì™€ DB íˆìŠ¤í† ë¦¬ ë³‘í•©
            merged_history = self._merge_conversation_history(
                conversation_history,
                db_history
            )

            # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
            self.conversation_manager.save_message(
                conversation_id=conversation_id,
                role='user',
                content=user_message,
                engine_type='',  # ì—”ì§„ íƒ€ì…ì€ ë‚˜ì¤‘ì— ì„¤ì •
                user_id=user_id
            )

            return {
                'conversation_id': conversation_id,
                'merged_history': merged_history
            }

        except Exception as e:
            logger.error(f"Error processing conversation: {e}")
            raise
    
    def track_usage(
        self,
        user_id: str,
        engine_type: str,
        input_text: str,
        output_text: str
    ) -> None:
        """
        ì‚¬ìš©ëŸ‰ ì¶”ì  (ì›”ë³„ + ì¼ë³„)
        """
        try:
            # í† í° ìˆ˜ ì¶”ì • (ëŒ€ëµì ì¸ ê³„ì‚°)
            input_tokens = len(input_text.split()) * 2
            output_tokens = len(output_text.split()) * 2
            total_tokens = input_tokens + output_tokens

            now = datetime.now(timezone.utc)
            year_month = now.strftime('%Y-%m')
            today = now.strftime('%Y-%m-%d')

            # yearMonthì— engineType í¬í•¨í•˜ì—¬ ì¤‘ë³µ ë°©ì§€
            year_month_with_engine = f"{year_month}#{engine_type.lower()}"

            # 1. ì›”ë³„ ì‚¬ìš©ëŸ‰ ê¸°ë¡ (ê¸°ì¡´)
            self.usage_table.update_item(
                Key={
                    'userId': user_id,
                    'yearMonth': year_month_with_engine
                },
                UpdateExpression="""
                    ADD requestCount :one,
                        inputTokens :input,
                        outputTokens :output,
                        totalTokens :total
                    SET engineType = :engine,
                        updatedAt = :now
                """,
                ExpressionAttributeValues={
                    ':one': 1,
                    ':input': input_tokens,
                    ':output': output_tokens,
                    ':total': total_tokens,
                    ':engine': engine_type,
                    ':now': now.isoformat()
                }
            )

            # 2. ì¼ë³„ ì‚¬ìš©ëŸ‰ ê¸°ë¡ (ì‹ ê·œ - ëŒ€ì‹œë³´ë“œ ë‚ ì§œ í•„í„°ë§ìš©)
            date_engine_key = f"{today}#{engine_type}"
            self.daily_usage_table.update_item(
                Key={
                    'userId': user_id,
                    'dateEngine': date_engine_key
                },
                UpdateExpression="""
                    ADD inputTokens :input,
                        outputTokens :output,
                        totalTokens :total,
                        messageCount :one
                    SET #date = :date,
                        engineType = :engine,
                        updatedAt = :now
                """,
                ExpressionAttributeNames={
                    '#date': 'date'  # 'date'ëŠ” ì˜ˆì•½ì–´ì´ë¯€ë¡œ ExpressionAttributeNames ì‚¬ìš©
                },
                ExpressionAttributeValues={
                    ':one': 1,
                    ':input': input_tokens,
                    ':output': output_tokens,
                    ':total': total_tokens,
                    ':date': today,
                    ':engine': engine_type,
                    ':now': now.isoformat()
                }
            )

            logger.info(f"Usage tracked for {user_id}: {input_tokens} + {output_tokens} tokens (monthly + daily)")

        except Exception as e:
            logger.error(f"Error tracking usage: {e}")
    
    def _merge_conversation_history(
        self,
        client_history: List[Dict] = None,
        db_history: List[Dict] = None
    ) -> List[Dict]:
        """
        í´ë¼ì´ì–¸íŠ¸ì™€ DBì˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ ë³‘í•©
        
        DB íˆìŠ¤í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•˜ë˜, í´ë¼ì´ì–¸íŠ¸ íˆìŠ¤í† ë¦¬ì—ë§Œ ìˆëŠ” ë©”ì‹œì§€ëŠ” ì¶”ê°€
        """
        client_history = client_history or []
        db_history = db_history or []
        merged = []

        # DB íˆìŠ¤í† ë¦¬ë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©
        for msg in db_history:
            merged.append({
                'role': msg.get('role', msg.get('type', 'user')),
                'content': msg.get('content', ''),
                'timestamp': msg.get('timestamp', '')
            })

        # í´ë¼ì´ì–¸íŠ¸ íˆìŠ¤í† ë¦¬ì—ë§Œ ìˆëŠ” ë©”ì‹œì§€ í™•ì¸ ë° ì¶”ê°€
        db_timestamps = {msg.get('timestamp') for msg in db_history if msg.get('timestamp')}
        
        for msg in client_history:
            timestamp = msg.get('timestamp')
            # íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ì—†ê±°ë‚˜ DBì— ì—†ëŠ” ë©”ì‹œì§€ëŠ” ìƒˆë¡œìš´ ë©”ì‹œì§€ë¡œ ê°„ì£¼
            if not timestamp or timestamp not in db_timestamps:
                # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ìµœê·¼ ë©”ì‹œì§€ì™€ ë¹„êµ
                content = msg.get('content', '')
                if not merged or merged[-1].get('content') != content:
                    merged.append({
                        'role': msg.get('role', 'user'),
                        'content': content,
                        'timestamp': timestamp or datetime.utcnow().isoformat() + 'Z'
                    })
        
        # ìµœëŒ€ 30ê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€ (ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ê´€ë¦¬) #ëŒ€í™”ê¸°ì–µê¸°ëŠ¥
        if len(merged) > 30:
            merged = merged[-30:]
        
        return merged
    
    def _build_system_prompt(
        self,
        guidelines: str,
        description: str,
        files: List[Dict],
        conversation_context: str,
        engine_type: str = "P1",
        user_role: str = "user"
    ) -> str:
        """
        Anthropic APIìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        Bedrockê³¼ ë™ì¼í•œ ì²´ê³„ì  í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        """
        # prompt_data êµ¬ì„±
        prompt_data = {
            'prompt': {
                'instruction': guidelines or "",
                'description': description or ""
            },
            'files': files or [],
            'userRole': user_role
        }

        # Bedrockê³¼ ë™ì¼í•œ ì²´ê³„ì  í”„ë¡¬í”„íŠ¸ ìƒì„±
        system_prompt = create_enhanced_system_prompt(
            prompt_data=prompt_data,
            engine_type=engine_type,
            use_enhanced=True,
            flexibility_level="strict"
        )

        return system_prompt
    
    def _format_conversation_for_bedrock(self, conversation_history: List[Dict]) -> str:
        """
        Bedrockì— ì „ë‹¬í•  ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…
        """
        if not conversation_history:
            return ""
        
        formatted_messages = []
        for msg in conversation_history[-10:]:  # ìµœê·¼ 10ê°œ ë©”ì‹œì§€ë§Œ ì‚¬ìš© #ëŒ€í™”ê¸°ì–µê¸°ëŠ¥
            role = msg.get('role', 'user')
            content = msg.get('content', '')
            if content:
                role_label = "ì‚¬ìš©ì" if role == 'user' else "AI"
                formatted_messages.append(f"{role_label}: {content}")
        
        if formatted_messages:
            return "\n\n=== ì´ì „ ëŒ€í™” ë‚´ìš© ===\n" + "\n\n".join(formatted_messages) + "\n\n=== í˜„ì¬ ì§ˆë¬¸ ==="
        
        return ""
    
    def _should_enable_web_search(self, user_message: str) -> bool:
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ì›¹ ê²€ìƒ‰ í™œì„±í™” í•„ìš”ì„± ë¶„ì„
        """
        try:
            # í™˜ê²½ë³€ìˆ˜ë¡œ ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ ì „ì—­ ë¹„í™œì„±í™” ê°€ëŠ¥
            if os.environ.get('ENABLE_NATIVE_WEB_SEARCH', 'true').lower() != 'true':
                return False
            
            # ê²€ìƒ‰ í‚¤ì›Œë“œë“¤
            search_keywords = [
                'ìµœì‹ ', 'ì˜¤ëŠ˜', 'í˜„ì¬', 'ë‰´ìŠ¤', 'ì£¼ê°€', 'í™˜ìœ¨', 'ë‚ ì”¨', 'íŠ¸ë Œë“œ',
                'ì†ë³´', 'ì‹¤ì‹œê°„', 'ë…¹ìƒ‰ì†Œë¹„', 'ì¹´ì´ìŠ¤íŠ¸', 'ë””ìŠ¤ì¹´ìš´íŠ¸', 'ë°°ë‹¹ë½',
                'ë¹„ë‹¨ë“±', 'ì–´ë””', 'ë¨¹ì„ê±°ë¦¬', 'ê´€ê¹‘', 'ë„ì‹œë½', 'ë§¤ë§¤', 'ì•Œë°”', 'ì¼ìë¦¬',
                'ìƒˆë¡œë‚˜ì˜¨', 'ì¶œì‹œ', 'ì—…ë°ì´íŠ¸', 'ëŒ€í‘œê²€', 'ìˆœì–‘', 'ì†ë³´', 'ì´ì¢…ëª…',
                'ì„¼í„°', 'ë¿Œë¦¬ì˜¤', 'ë¡œë³´íŠ¸', 'ê´€ë ¨', 'related', 'latest', 'today', 'news', 'current'
            ]
            
            # ì»¤ë¯¸ì…˜ í‘œí˜„ë“¤
            action_keywords = [
                'ì°¾ì•„ì¤˜', 'ì•Œì•„ì¤˜', 'ì„œì¹˜í•´', 'ê²€ìƒ‰í•´', 'í™•ì¸í•´',
                'ì—…ë°ì´íŠ¸ ëœ', 'ì •ë³´', 'ì–´ë–»ê²Œ'
            ]
            
            # í‚¤ì›Œë“œ ë§¤ì¹­
            message_lower = user_message.lower()
            
            # ê²€ìƒ‰ í‚¤ì›Œë“œ ë° ëª…ë ¹ ë§¤ì¹­
            for keyword in search_keywords + action_keywords:
                if keyword in message_lower:
                    logger.info(f"Web search enabled by keyword: {keyword}")
                    return True
            
            # íŠ¹ì • ì§ˆë¬¸ íŒ¨í„´ë“¤
            question_patterns = [
                'ì˜ˆì „ì—', 'ì˜ˆì „ê³¼', 'ë¹„êµ', 'ì°¨ì´', 'ì €ë²ˆê³¼', 'ì§€ë‚œ', 
                'ì§€ë‚œë²ˆ', 'ì „ë…„', 'ì „ë‹¬', 'ì „ì£¼', 'ì „ ëŒ€ë¹„', 
                'ì „ì— ë¹„í•´', 'ì „ ì„¸ëŒ€', 'ì „ê³¼', 'ì§€ë‚˜ê³ ',
                'ì•ˆ ë˜ë‚˜ìš”', 'ì•ˆ ë¼ìš”', 'ì•ˆ ë˜ëŠ”', 'ë˜ì§€ ì•ŠëŠ”', 
                'ì‘ë™ì•ˆí•´', 'ë©”ì´ì§€', 'ì•‰ì•¼', 'ê°œíŒ', 'ì´ë²ˆ', 'ì´ë‹¬', 'ê·¸ ì „', 'ë°°ê²½'
            ]
            
            for pattern in question_patterns:
                if pattern in message_lower:
                    logger.info(f"Web search enabled by pattern: {pattern}")
                    return True
                    
            return False
        
        except Exception as e:
            logger.error(f"Error in web search keyword detection: {str(e)}")
            return False