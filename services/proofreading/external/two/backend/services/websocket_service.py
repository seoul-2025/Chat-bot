"""
WebSocket ì„œë¹„ìŠ¤ - ì™„ì„± ë²„ì „ (Prompt Caching ì ìš©)
ìš°ìˆ˜ì‚¬ë¡€ ì½”ë“œë¥¼ ì°¸ê³ í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ê¸°ëŠ¥ ì¶”ê°€
ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨ ìºì‹±ìœ¼ë¡œ DynamoDB ì¡°íšŒ ìµœì†Œí™”
"""
import os
import sys
import json
import boto3
import logging
import time
from typing import Dict, List, Generator, Optional, Any, Tuple
from datetime import datetime, timezone
from decimal import Decimal

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from src.config.aws import AWS_REGION, DYNAMODB_TABLES
from lib.bedrock_client_enhanced import BedrockClientEnhanced
from lib.anthropic_client import AnthropicClient
from utils.logger import setup_logger

logger = setup_logger(__name__)

# ê¸€ë¡œë²Œ ìºì‹œ - Lambda ì»¨í…Œì´ë„ˆ ì¬ì‚¬ìš© ì‹œ ìœ ì§€ë¨
PROMPT_CACHE: Dict[str, Tuple[Dict[str, Any], float]] = {}
CACHE_TTL = 300  # 5ë¶„ (ì´ˆ ë‹¨ìœ„)

class WebSocketService:
    """WebSocket í†µì‹  ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        # AWS ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™”
        self.dynamodb = boto3.resource('dynamodb', region_name=AWS_REGION)
        self.conversations_table = self.dynamodb.Table(DYNAMODB_TABLES['conversations'])
        self.prompts_table = self.dynamodb.Table(DYNAMODB_TABLES['prompts'])
        self.usage_table = self.dynamodb.Table(DYNAMODB_TABLES['usage'])
        self.files_table = self.dynamodb.Table(DYNAMODB_TABLES['files'])  # íŒŒì¼ í…Œì´ë¸” ì¶”ê°€

        # AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (í™˜ê²½ë³€ìˆ˜ì— ë”°ë¼ ì„ íƒ)
        use_anthropic = os.environ.get('USE_ANTHROPIC_API', 'false').lower() == 'true'
        if use_anthropic:
            self.ai_client = AnthropicClient()
            self.ai_provider = 'anthropic'
            logger.info("Using Anthropic API (Claude 4.5 Opus)")
        else:
            self.ai_client = BedrockClientEnhanced()
            self.ai_provider = 'bedrock'
            logger.info("Using AWS Bedrock (Claude 3.5 Sonnet)")
        
        # Bedrock í´ë¼ì´ì–¸íŠ¸ë„ í´ë°±ìš©ìœ¼ë¡œ ìœ ì§€
        self.bedrock_client = BedrockClientEnhanced()

        # ëŒ€í™” ê´€ë¦¬ì
        from handlers.websocket.conversation_manager import ConversationManager
        self.conversation_manager = ConversationManager()

        logger.info("WebSocketService initialized")
    
    def _load_prompt_from_dynamodb(self, engine_type: str) -> Dict[str, Any]:
        """
        DynamoDBì—ì„œ í”„ë¡¬í”„íŠ¸ì™€ íŒŒì¼ ë¡œë“œ (ì¸ë©”ëª¨ë¦¬ ìºì‹± ì ìš©)

        ìºì‹œ íˆíŠ¸ ì‹œ DB ì¡°íšŒë¥¼ ìƒëµí•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ
        """
        global PROMPT_CACHE
        now = time.time()

        # ìºì‹œ í™•ì¸
        if engine_type in PROMPT_CACHE:
            cached_data, cached_time = PROMPT_CACHE[engine_type]
            age = now - cached_time

            if age < CACHE_TTL:
                logger.info(f"âœ… Cache HIT for {engine_type} (age: {age:.1f}s) - DB ì¡°íšŒ ìƒëµ")
                return cached_data
            else:
                logger.info(f"â° Cache EXPIRED for {engine_type} (age: {age:.1f}s) - ì¬ì¡°íšŒ")
        else:
            logger.info(f"âŒ Cache MISS for {engine_type} - ìµœì´ˆ ì¡°íšŒ")

        # ìºì‹œ ë¯¸ìŠ¤ ë˜ëŠ” ë§Œë£Œ - DBì—ì„œ ë¡œë“œ
        prompt_data = self._fetch_prompt_from_db(engine_type)

        # ìºì‹œ ì—…ë°ì´íŠ¸
        PROMPT_CACHE[engine_type] = (prompt_data, now)
        logger.info(f"ğŸ’¾ Cached prompt for {engine_type} "
                   f"({len(prompt_data.get('files', []))} files, "
                   f"{len(str(prompt_data))} bytes)")

        return prompt_data

    def _fetch_prompt_from_db(self, engine_type: str) -> Dict[str, Any]:
        """
        ì‹¤ì œ DB ì¡°íšŒ ë¡œì§ (ìºì‹± ì „ìš©)
        ìºì‹œ ë¯¸ìŠ¤ ì‹œì—ë§Œ í˜¸ì¶œë¨
        """
        try:
            start_time = time.time()

            # í”„ë¡¬í”„íŠ¸ í…Œì´ë¸”ì—ì„œ ê¸°ë³¸ ì •ë³´ ë¡œë“œ (id í‚¤ ì‚¬ìš©)
            response = self.prompts_table.get_item(Key={'id': engine_type})
            if 'Item' in response:
                item = response['Item']
                prompt_data = {
                    'instruction': item.get('instruction', ''),
                    'description': item.get('description', ''),
                    'files': []
                }

                # files í…Œì´ë¸”ì—ì„œ ê´€ë ¨ íŒŒì¼ë“¤ ë¡œë“œ
                try:
                    files_response = self.files_table.scan(
                        FilterExpression='promptId = :promptId',
                        ExpressionAttributeValues={':promptId': engine_type}
                    )

                    if 'Items' in files_response:
                        for file_item in files_response['Items']:
                            prompt_data['files'].append({
                                'fileName': file_item.get('fileName', ''),
                                'fileContent': file_item.get('fileContent', ''),
                                'fileType': 'text'  # ê¸°ë³¸ê°’
                            })
                except Exception as fe:
                    logger.error(f"Error loading files: {str(fe)}")

                elapsed = (time.time() - start_time) * 1000
                logger.info(f"ğŸ” DB fetch for {engine_type}: "
                          f"{len(prompt_data['files'])} files in {elapsed:.0f}ms")

                return prompt_data
            else:
                logger.warning(f"No prompt found for engine type: {engine_type}")
                return {'instruction': '', 'description': '', 'files': []}
        except Exception as e:
            logger.error(f"Error loading prompt from DynamoDB: {str(e)}")
            return {'instruction': '', 'description': '', 'files': []}

    
    def stream_response(
        self,
        user_message: str,
        engine_type: str,
        conversation_id: str,
        user_id: str,
        conversation_history: List[Dict],
        user_role: str = 'user'
    ) -> Generator[str, None, None]:
        """
        Bedrock ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
        
        Yields:
            str: ì‘ë‹µ ì²­í¬
        """
        try:
            # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
            formatted_history = self._format_conversation_for_bedrock(conversation_history)
            
            # DynamoDBì—ì„œ í”„ë¡¬í”„íŠ¸ì™€ íŒŒì¼ í†µí•© ë¡œë“œ
            prompt_data = self._load_prompt_from_dynamodb(engine_type)
            logger.info(f"Loaded prompt for {engine_type}: instruction={len(prompt_data.get('instruction', ''))} chars")

            logger.info(f"Streaming response for engine {engine_type}")
            logger.info(f"Conversation context: {len(formatted_history)} messages")

            # AI ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ (Anthropic ë˜ëŠ” Bedrock)
            total_response = ""
            
            # Anthropic API ì‚¬ìš© ì‹œ
            if self.ai_provider == 'anthropic' and hasattr(self.ai_client, 'stream_response'):
                try:
                    logger.info(f"Using Anthropic API for {engine_type}")
                    
                    # í”„ë¡¬í”„íŠ¸ì™€ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê²°í•©
                    full_system_prompt = self._build_system_prompt(
                        guidelines=prompt_data.get('instruction', ''),
                        description=prompt_data.get('description', ''),
                        files=prompt_data.get('files', []),
                        conversation_context=formatted_history
                    )
                    
                    # ì›¹ ê²€ìƒ‰ í™œì„±í™” ì—¬ë¶€ íŒë‹¨
                    enable_web_search = self._should_enable_web_search(user_message)
                    
                    for chunk in self.ai_client.stream_response(
                        user_message=user_message,
                        system_prompt=full_system_prompt,
                        conversation_context=formatted_history,
                        enable_web_search=enable_web_search,
                        web_search_max_uses=int(os.environ.get('WEB_SEARCH_MAX_USES', '5'))
                    ):
                        total_response += chunk
                        yield chunk
                        
                except Exception as e:
                    # Anthropic API ì‹¤íŒ¨ ì‹œ Bedrockìœ¼ë¡œ í´ë°±
                    if os.environ.get('FALLBACK_TO_BEDROCK', 'true').lower() == 'true':
                        logger.warning(f"Anthropic API failed, falling back to Bedrock: {str(e)}")
                        total_response = ""
                        for chunk in self.bedrock_client.stream_bedrock(
                            user_message=user_message,
                            engine_type=engine_type,
                            conversation_context=formatted_history,
                            user_role=user_role,
                            guidelines=prompt_data.get('instruction'),
                            description=prompt_data.get('description'),
                            files=prompt_data.get('files', [])
                        ):
                            total_response += chunk
                            yield chunk
                    else:
                        raise
            
            # Bedrock ì‚¬ìš© ì‹œ (ê¸°ì¡´ ë¡œì§)
            else:
                for chunk in self.bedrock_client.stream_bedrock(
                    user_message=user_message,
                    engine_type=engine_type,
                    conversation_context=formatted_history,  # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬
                    user_role=user_role,
                    guidelines=prompt_data.get('instruction'),  # DynamoDB instruction ì „ë‹¬
                    description=prompt_data.get('description'),  # DynamoDB description ì „ë‹¬
                    files=prompt_data.get('files', [])  # DynamoDB files ì „ë‹¬
                ):
                    total_response += chunk
                    yield chunk
            
            # AI ì‘ë‹µì„ ëŒ€í™”ì— ì €ì¥
            if total_response:
                self.conversation_manager.save_message(
                    conversation_id=conversation_id,
                    role='assistant',
                    content=total_response,
                    engine_type=engine_type,
                    user_id=user_id
                )
                logger.info(f"AI response saved: {len(total_response)} chars")
            
        except Exception as e:
            logger.error(f"Error streaming response: {str(e)}")
            yield f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def process_message(
        self,
        user_message: str,
        engine_type: str,
        conversation_id: Optional[str],
        user_id: str,
        conversation_history: List[Dict],
        user_role: str = 'user'
    ) -> Dict[str, Any]:
        """
        ë©”ì‹œì§€ ì²˜ë¦¬ ë° ëŒ€í™” íˆìŠ¤í† ë¦¬ ë³‘í•©

        Returns:
            Dict containing conversation_id and merged_history
        """
        try:
            # ëŒ€í™” IDê°€ ì—†ìœ¼ë©´ ìƒì„±
            if not conversation_id:
                import uuid
                conversation_id = str(uuid.uuid4())
                logger.info(f"New conversation created: {conversation_id}")

            # DBì—ì„œ ê¸°ì¡´ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ
            db_history = self.conversation_manager.get_conversation_history(
                conversation_id,
                limit=20  # ìµœê·¼ 20ê°œ ë©”ì‹œì§€
            )

            # í´ë¼ì´ì–¸íŠ¸ íˆìŠ¤í† ë¦¬ì™€ DB íˆìŠ¤í† ë¦¬ ë³‘í•©
            merged_history = self._merge_conversation_history(
                client_history=conversation_history,
                db_history=db_history
            )

            # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™”ì— ì €ì¥
            self.conversation_manager.save_message(
                conversation_id=conversation_id,
                role='user',
                content=user_message,
                engine_type=engine_type,
                user_id=user_id
            )

            # ë³‘í•©ëœ íˆìŠ¤í† ë¦¬ì— í˜„ì¬ ë©”ì‹œì§€ ì¶”ê°€
            merged_history.append({
                'role': 'user',
                'content': user_message,
                'timestamp': datetime.utcnow().isoformat() + 'Z'
            })

            logger.info(f"Processed message for conversation {conversation_id}")
            logger.info(f"Merged history length: {len(merged_history)}")

            return {
                'conversation_id': conversation_id,
                'merged_history': merged_history
            }

        except Exception as e:
            logger.error(f"Error processing message: {str(e)}")
            raise

    def process_conversation(
        self,
        user_message: str,
        conversation_id: str,
        user_id: str,
        conversation_history: List[Dict],
        user_role: str = 'user'
    ) -> Dict:
        """
        ëŒ€í™” ì²˜ë¦¬ ë° íˆìŠ¤í† ë¦¬ ë³‘í•©

        Returns:
            Dict: conversation_idì™€ ë³‘í•©ëœ íˆìŠ¤í† ë¦¬
        """
        try:
            # ëŒ€í™” ID ìƒì„± ë˜ëŠ” ê²€ì¦
            if not conversation_id:
                # ìƒˆ ëŒ€í™” ìƒì„±
                conversation_id = f"{user_id}_{datetime.now().timestamp()}"
                logger.info(f"Created new conversation: {conversation_id}")

            # DBì—ì„œ ê¸°ì¡´ ëŒ€í™” ë¡œë“œ
            db_history = []
            if conversation_id:
                try:
                    response = self.conversations_table.get_item(
                        Key={
                            'userId': user_id,
                            'conversationId': conversation_id
                        }
                    )
                    if 'Item' in response:
                        db_history = response['Item'].get('messages', [])
                        logger.info(f"Loaded {len(db_history)} messages from DB")
                except Exception as e:
                    logger.error(f"Error loading conversation from DB: {e}")

            # í´ë¼ì´ì–¸íŠ¸ì™€ DB íˆìŠ¤í† ë¦¬ ë³‘í•©
            merged_history = self._merge_conversation_history(
                conversation_history,
                db_history
            )

            # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
            self.conversation_manager.save_message(
                conversation_id=conversation_id,
                role='user',
                content=user_message,
                engine_type='',  # ì—”ì§„ íƒ€ì…ì€ ë‚˜ì¤‘ì— ì„¤ì •
                user_id=user_id
            )

            return {
                'conversation_id': conversation_id,
                'merged_history': merged_history
            }

        except Exception as e:
            logger.error(f"Error processing conversation: {e}")
            raise
    
    def track_usage(
        self,
        user_id: str,
        engine_type: str,
        input_text: str,
        output_text: str
    ) -> None:
        """
        ì‚¬ìš©ëŸ‰ ì¶”ì 
        """
        try:
            # í† í° ìˆ˜ ì¶”ì • (ëŒ€ëµì ì¸ ê³„ì‚°)
            input_tokens = len(input_text.split()) * 2
            output_tokens = len(output_text.split()) * 2
            
            # ì‚¬ìš©ëŸ‰ ê¸°ë¡
            year_month = datetime.now(timezone.utc).strftime('%Y-%m')
            # yearMonthì— engineType í¬í•¨í•˜ì—¬ ì¤‘ë³µ ë°©ì§€
            year_month_with_engine = f"{year_month}#{engine_type.lower()}"

            # ì›ìì  ì—…ë°ì´íŠ¸
            self.usage_table.update_item(
                Key={
                    'userId': user_id,
                    'yearMonth': year_month_with_engine
                },
                UpdateExpression="""
                    ADD requestCount :one,
                        inputTokens :input,
                        outputTokens :output,
                        totalTokens :total
                    SET engineType = :engine,
                        updatedAt = :now
                """,
                ExpressionAttributeValues={
                    ':one': 1,
                    ':input': input_tokens,
                    ':output': output_tokens,
                    ':total': input_tokens + output_tokens,
                    ':engine': engine_type,
                    ':now': datetime.now(timezone.utc).isoformat()
                }
            )
            
            logger.info(f"Usage tracked for {user_id}: {input_tokens} + {output_tokens} tokens")
            
        except Exception as e:
            logger.error(f"Error tracking usage: {e}")
    
    def _merge_conversation_history(
        self,
        client_history: List[Dict] = None,
        db_history: List[Dict] = None
    ) -> List[Dict]:
        """
        í´ë¼ì´ì–¸íŠ¸ì™€ DBì˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ ë³‘í•©
        
        DB íˆìŠ¤í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•˜ë˜, í´ë¼ì´ì–¸íŠ¸ íˆìŠ¤í† ë¦¬ì—ë§Œ ìˆëŠ” ë©”ì‹œì§€ëŠ” ì¶”ê°€
        """
        client_history = client_history or []
        db_history = db_history or []
        merged = []

        # DB íˆìŠ¤í† ë¦¬ë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©
        for msg in db_history:
            merged.append({
                'role': msg.get('role', msg.get('type', 'user')),
                'content': msg.get('content', ''),
                'timestamp': msg.get('timestamp', '')
            })

        # í´ë¼ì´ì–¸íŠ¸ íˆìŠ¤í† ë¦¬ì—ë§Œ ìˆëŠ” ë©”ì‹œì§€ í™•ì¸ ë° ì¶”ê°€
        db_timestamps = {msg.get('timestamp') for msg in db_history if msg.get('timestamp')}
        
        for msg in client_history:
            timestamp = msg.get('timestamp')
            # íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ì—†ê±°ë‚˜ DBì— ì—†ëŠ” ë©”ì‹œì§€ëŠ” ìƒˆë¡œìš´ ë©”ì‹œì§€ë¡œ ê°„ì£¼
            if not timestamp or timestamp not in db_timestamps:
                # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ìµœê·¼ ë©”ì‹œì§€ì™€ ë¹„êµ
                content = msg.get('content', '')
                if not merged or merged[-1].get('content') != content:
                    merged.append({
                        'role': msg.get('role', 'user'),
                        'content': content,
                        'timestamp': timestamp or datetime.utcnow().isoformat() + 'Z'
                    })
        
        # ìµœëŒ€ 30ê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€ (ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ê´€ë¦¬) #ëŒ€í™”ê¸°ì–µê¸°ëŠ¥
        if len(merged) > 30:
            merged = merged[-30:]
        
        return merged
    
    def _build_system_prompt(
        self,
        guidelines: str,
        description: str,
        files: List[Dict],
        conversation_context: str
    ) -> str:
        """
        Anthropic APIìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        """
        prompt_parts = []
        
        # ê¸°ë³¸ ê°€ì´ë“œë¼ì¸
        if guidelines:
            prompt_parts.append(guidelines)
        
        # ì„¤ëª… ì¶”ê°€
        if description:
            prompt_parts.append(f"\n\n=== ì¶”ê°€ ì„¤ëª… ===\n{description}")
        
        # íŒŒì¼ ë‚´ìš© ì¶”ê°€
        if files:
            prompt_parts.append("\n\n=== ì°¸ê³  ë¬¸ì„œ ===")
            for file in files:
                file_name = file.get('fileName', 'Unknown')
                file_content = file.get('fileContent', '')
                if file_content:
                    prompt_parts.append(f"\n[{file_name}]\n{file_content}")
        
        # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        if conversation_context:
            prompt_parts.append(f"\n\n{conversation_context}")
        
        return "\n".join(prompt_parts)
    
    def _format_conversation_for_bedrock(self, conversation_history: List[Dict]) -> str:
        """
        Bedrockì— ì „ë‹¬í•  ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…
        """
        if not conversation_history:
            return ""
        
        formatted_messages = []
        for msg in conversation_history[-10:]:  # ìµœê·¼ 10ê°œ ë©”ì‹œì§€ë§Œ ì‚¬ìš© #ëŒ€í™”ê¸°ì–µê¸°ëŠ¥
            role = msg.get('role', 'user')
            content = msg.get('content', '')
            if content:
                role_label = "ì‚¬ìš©ì" if role == 'user' else "AI"
                formatted_messages.append(f"{role_label}: {content}")
        
        if formatted_messages:
            return "\n\n=== ì´ì „ ëŒ€í™” ë‚´ìš© ===\n" + "\n\n".join(formatted_messages) + "\n\n=== í˜„ì¬ ì§ˆë¬¸ ==="
        
        return ""
    
    def _should_enable_web_search(self, user_message: str) -> bool:
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ì›¹ ê²€ìƒ‰ í™œì„±í™” í•„ìš”ì„± ë¶„ì„
        """
        try:
            # í™˜ê²½ë³€ìˆ˜ë¡œ ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ ì „ì—­ ë¹„í™œì„±í™” ê°€ëŠ¥
            if os.environ.get('ENABLE_NATIVE_WEB_SEARCH', 'true').lower() != 'true':
                return False
            
            # ê²€ìƒ‰ í‚¤ì›Œë“œë“¤
            search_keywords = [
                'ìµœì‹ ', 'ì˜¤ëŠ˜', 'í˜„ì¬', 'ë‰´ìŠ¤', 'ì£¼ê°€', 'í™˜ìœ¨', 'ë‚ ì”¨', 'íŠ¸ë Œë“œ',
                'ì†ë³´', 'ì‹¤ì‹œê°„', 'ë…¹ìƒ‰ì†Œë¹„', 'ì¹´ì´ìŠ¤íŠ¸', 'ë””ìŠ¤ì¹´ìš´íŠ¸', 'ë°°ë‹¹ë½',
                'ë¹„ë‹¨ë“±', 'ì–´ë””', 'ë¨¹ì„ê±°ë¦¬', 'ê´€ê¹‘', 'ë„ì‹œë½', 'ë§¤ë§¤', 'ì•Œë°”', 'ì¼ìë¦¬',
                'ìƒˆë¡œë‚˜ì˜¨', 'ì¶œì‹œ', 'ì—…ë°ì´íŠ¸', 'ëŒ€í‘œê²€', 'ìˆœì–‘', 'ì†ë³´', 'ì´ì¢…ëª…',
                'ì„¼í„°', 'ë¿Œë¦¬ì˜¤', 'ë¡œë³´íŠ¸', 'ê´€ë ¨', 'related', 'latest', 'today', 'news', 'current'
            ]
            
            # ì»¤ë¯¸ì…˜ í‘œí˜„ë“¤
            action_keywords = [
                'ì°¾ì•„ì¤˜', 'ì•Œì•„ì¤˜', 'ì„œì¹˜í•´', 'ê²€ìƒ‰í•´', 'í™•ì¸í•´',
                'ì—…ë°ì´íŠ¸ ëœ', 'ì •ë³´', 'ì–´ë–»ê²Œ'
            ]
            
            # í‚¤ì›Œë“œ ë§¤ì¹­
            message_lower = user_message.lower()
            
            # ê²€ìƒ‰ í‚¤ì›Œë“œ ë° ëª…ë ¹ ë§¤ì¹­
            for keyword in search_keywords + action_keywords:
                if keyword in message_lower:
                    logger.info(f"Web search enabled by keyword: {keyword}")
                    return True
            
            # íŠ¹ì • ì§ˆë¬¸ íŒ¨í„´ë“¤
            question_patterns = [
                'ì˜ˆì „ì—', 'ì˜ˆì „ê³¼', 'ë¹„êµ', 'ì°¨ì´', 'ì €ë²ˆê³¼', 'ì§€ë‚œ', 
                'ì§€ë‚œë²ˆ', 'ì „ë…„', 'ì „ë‹¬', 'ì „ì£¼', 'ì „ ëŒ€ë¹„', 
                'ì „ì— ë¹„í•´', 'ì „ ì„¸ëŒ€', 'ì „ê³¼', 'ì§€ë‚˜ê³ ',
                'ì•ˆ ë˜ë‚˜ìš”', 'ì•ˆ ë¼ìš”', 'ì•ˆ ë˜ëŠ”', 'ë˜ì§€ ì•ŠëŠ”', 
                'ì‘ë™ì•ˆí•´', 'ë©”ì´ì§€', 'ì•‰ì•¼', 'ê°œíŒ', 'ì´ë²ˆ', 'ì´ë‹¬', 'ê·¸ ì „', 'ë°°ê²½'
            ]
            
            for pattern in question_patterns:
                if pattern in message_lower:
                    logger.info(f"Web search enabled by pattern: {pattern}")
                    return True
                    
            return False
        
        except Exception as e:
            logger.error(f"Error in web search keyword detection: {str(e)}")
            return False