"""
WebSocket Service with Dual AI Provider Support
Bedrock + Anthropic API ë³‘í–‰ ì§€ì› ë²„ì „
"""
import json
import boto3
import logging
import time
from datetime import datetime, timezone, timedelta
from typing import List, Dict, Any, Optional, Generator
import uuid
import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from src.config.aws import AWS_REGION, DYNAMODB_TABLES

from handlers.websocket.conversation_manager import ConversationManager
from lib.perplexity_client import PerplexityClient
from utils.logger import setup_logger

logger = setup_logger(__name__)

# ê¸€ë¡œë²Œ ìºì‹œ - Lambda ì»¨í…Œì´ë„ˆ ì¬ì‚¬ìš© ì‹œ ìœ ì§€ë¨ (ì˜êµ¬ ìºì‹œ)
PROMPT_CACHE: Dict[str, Dict[str, Any]] = {}

# DynamoDB í´ë¼ì´ì–¸íŠ¸ - í”„ë¡¬í”„íŠ¸ í…Œì´ë¸” ì ‘ê·¼ìš©
dynamodb = boto3.resource('dynamodb', region_name=AWS_REGION)

# f1 ì„œë¹„ìŠ¤ìš© í…Œì´ë¸” ì„¤ì •
PROMPTS_TABLE_NAME = os.environ.get('PROMPTS_TABLE', 'p2-two-prompts-two')
FILES_TABLE_NAME = os.environ.get('FILES_TABLE', 'p2-two-files-two')

prompts_table = dynamodb.Table(PROMPTS_TABLE_NAME)
files_table = dynamodb.Table(FILES_TABLE_NAME)

logger.info(f"Using prompts table: {PROMPTS_TABLE_NAME}")
logger.info(f"Using files table: {FILES_TABLE_NAME}")


def get_ai_client(user_id: str = None, engine_type: str = None):
    """
    í™˜ê²½ë³€ìˆ˜ì™€ ì‚¬ìš©ì ì •ë³´ì— ë”°ë¼ ì ì ˆí•œ AI í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜
    
    ìš°ì„ ìˆœìœ„:
    1. í™˜ê²½ë³€ìˆ˜ AI_PROVIDER
    2. í™˜ê²½ë³€ìˆ˜ USE_ANTHROPIC_API
    3. ì‚¬ìš©ìë³„ ì„¤ì • (í”„ë¦¬ë¯¸ì—„ ì‚¬ìš©ì ë“±)
    4. ê¸°ë³¸ê°’: Bedrock
    """
    try:
        # 1. ëª…ì‹œì  í”„ë¡œë°”ì´ë” ì„¤ì •
        ai_provider = os.environ.get('AI_PROVIDER', '').lower()
        
        if ai_provider == 'anthropic_api' or ai_provider == 'anthropic':
            logger.info("ğŸ¯ AI Provider: Anthropic API (via AI_PROVIDER env)")
            from lib.anthropic_client import AnthropicClient
            return AnthropicClient()
        elif ai_provider == 'bedrock':
            logger.info("ğŸ¯ AI Provider: AWS Bedrock (via AI_PROVIDER env)")
            from lib.bedrock_client_enhanced import BedrockClientEnhanced
            return BedrockClientEnhanced()
        
        # 2. USE_ANTHROPIC_API í™˜ê²½ë³€ìˆ˜ í™•ì¸
        use_anthropic = os.environ.get('USE_ANTHROPIC_API', 'false').lower() == 'true'
        
        if use_anthropic:
            logger.info("ğŸ¯ AI Provider: Anthropic API (via USE_ANTHROPIC_API env)")
            from lib.anthropic_client import AnthropicClient
            return AnthropicClient()
        
        # 3. ì‚¬ìš©ìë³„ ì„¤ì • (ì˜ˆ: í”„ë¦¬ë¯¸ì—„ ì‚¬ìš©ì)
        if user_id and engine_type:
            # íŠ¹ì • ì—”ì§„ íƒ€ì…ì— ëŒ€í•´ Anthropic ì‚¬ìš©
            premium_engines = os.environ.get('ANTHROPIC_ENGINES', '').split(',')
            if engine_type in premium_engines:
                logger.info(f"ğŸ¯ AI Provider: Anthropic API (engine {engine_type} in premium list)")
                from lib.anthropic_client import AnthropicClient
                return AnthropicClient()
            
            # sedaily.com ë„ë©”ì¸ ì‚¬ìš©ìëŠ” Anthropic API ì‚¬ìš© (ì˜µì…˜)
            if '@sedaily.com' in str(user_id) and os.environ.get('ANTHROPIC_FOR_INTERNAL', 'false').lower() == 'true':
                logger.info(f"ğŸ¯ AI Provider: Anthropic API (internal user: {user_id})")
                from lib.anthropic_client import AnthropicClient
                return AnthropicClient()
        
        # 4. ê¸°ë³¸ê°’: Bedrock
        logger.info("ğŸ¯ AI Provider: AWS Bedrock (default)")
        from lib.bedrock_client_enhanced import BedrockClientEnhanced
        return BedrockClientEnhanced()
        
    except ImportError as e:
        logger.error(f"Failed to import AI client: {str(e)}")
        logger.warning("âš ï¸ Falling back to Bedrock due to import error")
        from lib.bedrock_client_enhanced import BedrockClientEnhanced
        return BedrockClientEnhanced()
    except Exception as e:
        logger.error(f"Error selecting AI client: {str(e)}")
        logger.warning("âš ï¸ Falling back to Bedrock due to error")
        from lib.bedrock_client_enhanced import BedrockClientEnhanced
        return BedrockClientEnhanced()


class WebSocketService:
    """WebSocket ë©”ì‹œì§€ ì²˜ë¦¬ ì„œë¹„ìŠ¤ - Dual AI Provider Support"""

    def __init__(self):
        self.conversation_manager = ConversationManager()
        self.prompts_table = prompts_table
        self.files_table = files_table
        self.perplexity_client = PerplexityClient()
        # AI í´ë¼ì´ì–¸íŠ¸ëŠ” ë™ì ìœ¼ë¡œ ì„ íƒë¨
        self.ai_client = None
        logger.info("WebSocketService initialized with dual AI provider support")

    def _get_or_create_ai_client(self, user_id: str = None, engine_type: str = None):
        """AI í´ë¼ì´ì–¸íŠ¸ë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜ ìƒì„±"""
        if not self.ai_client:
            self.ai_client = get_ai_client(user_id, engine_type)
        return self.ai_client

    def process_message(
        self,
        user_message: str,
        engine_type: str,
        conversation_id: Optional[str],
        user_id: str,
        conversation_history: List[Dict],
        user_role: str = 'user'
    ) -> Dict[str, Any]:
        """
        ë©”ì‹œì§€ ì²˜ë¦¬ ë° ëŒ€í™” íˆìŠ¤í† ë¦¬ ë³‘í•©

        Returns:
            Dict containing conversation_id and merged_history
        """
        try:
            # ëŒ€í™” IDê°€ ì—†ìœ¼ë©´ ìƒì„±
            if not conversation_id:
                conversation_id = str(uuid.uuid4())
                logger.info(f"New conversation created: {conversation_id}")

            # DBì—ì„œ ê¸°ì¡´ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ
            db_history = self.conversation_manager.get_conversation_history(
                conversation_id,
                limit=20  # ìµœê·¼ 20ê°œ ë©”ì‹œì§€
            )

            # í´ë¼ì´ì–¸íŠ¸ íˆìŠ¤í† ë¦¬ì™€ DB íˆìŠ¤í† ë¦¬ ë³‘í•©
            merged_history = self._merge_conversation_history(
                client_history=conversation_history,
                db_history=db_history
            )

            # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™”ì— ì €ì¥
            self.conversation_manager.save_message(
                conversation_id=conversation_id,
                role='user',
                content=user_message,
                engine_type=engine_type,
                user_id=user_id
            )

            # ë³‘í•©ëœ íˆìŠ¤í† ë¦¬ì— í˜„ì¬ ë©”ì‹œì§€ ì¶”ê°€
            merged_history.append({
                'role': 'user',
                'content': user_message,
                'timestamp': datetime.utcnow().isoformat() + 'Z'
            })

            logger.info(f"Processed message for conversation {conversation_id}")
            logger.info(f"Merged history length: {len(merged_history)}")

            return {
                'conversation_id': conversation_id,
                'merged_history': merged_history
            }

        except Exception as e:
            logger.error(f"Error processing message: {str(e)}")
            raise

    def _load_prompt_from_dynamodb(self, engine_type: str) -> Dict[str, Any]:
        """
        DynamoDBì—ì„œ í”„ë¡¬í”„íŠ¸ì™€ íŒŒì¼ ë¡œë“œ (ì˜êµ¬ ì¸ë©”ëª¨ë¦¬ ìºì‹±)
        """
        global PROMPT_CACHE

        # ìºì‹œ í™•ì¸
        if engine_type in PROMPT_CACHE:
            logger.info(f"âœ… Cache HIT for {engine_type} - DB query skipped")
            return PROMPT_CACHE[engine_type]

        logger.info(f"âŒ Cache MISS for {engine_type} - fetching from DB")

        # ìºì‹œ ë¯¸ìŠ¤ - DBì—ì„œ ë¡œë“œ
        prompt_data = self._fetch_prompt_from_db(engine_type)

        # ìºì‹œ ì—…ë°ì´íŠ¸ (ì˜êµ¬ ì €ì¥)
        PROMPT_CACHE[engine_type] = prompt_data
        logger.info(f"ğŸ’¾ Permanently cached prompt for {engine_type}")

        return prompt_data

    def _fetch_prompt_from_db(self, engine_type: str) -> Dict[str, Any]:
        """ì‹¤ì œ DB ì¡°íšŒ ë¡œì§"""
        try:
            start_time = time.time()

            # í”„ë¡¬í”„íŠ¸ í…Œì´ë¸”ì—ì„œ ê¸°ë³¸ ì •ë³´ ë¡œë“œ
            response = self.prompts_table.get_item(
                Key={
                    'engineType': engine_type,
                    'promptId': engine_type
                }
            )
            if 'Item' in response:
                item = response['Item']
                prompt_data = {
                    'instruction': item.get('instruction', ''),
                    'description': item.get('description', ''),
                    'files': []
                }

                # files í…Œì´ë¸”ì—ì„œ ê´€ë ¨ íŒŒì¼ë“¤ ë¡œë“œ
                try:
                    files_response = self.files_table.scan()

                    if 'Items' in files_response:
                        for file_item in files_response['Items']:
                            prompt_data['files'].append({
                                'fileName': file_item.get('fileName', ''),
                                'fileContent': file_item.get('fileContent', ''),
                                'fileType': 'text'
                            })
                except Exception as fe:
                    logger.error(f"Error loading files: {str(fe)}")

                elapsed = (time.time() - start_time) * 1000
                logger.info(f"ğŸ” DB fetch for {engine_type} in {elapsed:.0f}ms (will be cached permanently)")

                return prompt_data
            else:
                logger.warning(f"No prompt found for engine type: {engine_type}")
                return {'instruction': '', 'description': '', 'files': []}
        except Exception as e:
            logger.error(f"Error loading prompt from DynamoDB: {str(e)}")
            return {'instruction': '', 'description': '', 'files': []}

    def stream_response(
        self,
        user_message: str,
        engine_type: str,
        conversation_id: str,
        user_id: str,
        conversation_history: List[Dict],
        user_role: str = 'user'
    ) -> Generator[str, None, None]:
        """
        AI ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± (Bedrock/Anthropic ìë™ ì„ íƒ)

        Yields:
            str: ì‘ë‹µ ì²­í¬
        """
        try:
            # AI í´ë¼ì´ì–¸íŠ¸ ì„ íƒ
            ai_client = self._get_or_create_ai_client(user_id, engine_type)
            
            # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
            formatted_history = self._format_conversation_for_bedrock(conversation_history)

            # DynamoDBì—ì„œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
            prompt_data = self._load_prompt_from_dynamodb(engine_type)

            logger.info(f"=== Prompt Data Loaded for {engine_type} ===")
            logger.info(f"AI Client: {ai_client.__class__.__name__}")
            
            # ì›¹ ê²€ìƒ‰ ìˆ˜í–‰ (ì˜µì…˜)
            web_search_result = None
            enable_search = os.environ.get('ENABLE_WEB_SEARCH', 'false').lower() == 'true'
            
            if enable_search:
                logger.info(f"ğŸ” Web search ENABLED")
                try:
                    web_search_result = self.perplexity_client.search(user_message, enable=True)
                    if web_search_result:
                        logger.info(f"âœ… Web search completed")
                except Exception as e:
                    logger.error(f"âŒ Web search failed: {str(e)}")

            # ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë©”ì‹œì§€ì— ì¶”ê°€
            enhanced_message = user_message
            if web_search_result:
                enhanced_message = f"[ìµœì‹  ì›¹ ê²€ìƒ‰ ì •ë³´]\n{web_search_result}\n\n[ì‚¬ìš©ì ì§ˆë¬¸]\n{user_message}"

            total_response = ""
            retry_with_bedrock = False
            
            try:
                # AI í´ë¼ì´ì–¸íŠ¸ í˜¸ì¶œ (Bedrock í˜¸í™˜ ì¸í„°í˜ì´ìŠ¤)
                for chunk in ai_client.stream_bedrock(
                    user_message=enhanced_message,
                    engine_type=engine_type,
                    conversation_context=formatted_history,
                    user_role=user_role,
                    guidelines=prompt_data.get('instruction'),
                    description=prompt_data.get('description'),
                    files=prompt_data.get('files', [])
                ):
                    total_response += chunk
                    yield chunk
                    
            except Exception as e:
                # Anthropic API ì˜¤ë¥˜ ì‹œ Bedrock í´ë°±
                if 'RateLimitError' in str(e.__class__.__name__) or 'anthropic' in str(e).lower():
                    if os.environ.get('FALLBACK_TO_BEDROCK', 'true').lower() == 'true':
                        logger.warning(f"âš ï¸ Anthropic API error, falling back to Bedrock: {str(e)}")
                        retry_with_bedrock = True
                    else:
                        raise
                else:
                    raise
            
            # Bedrock í´ë°± ì²˜ë¦¬
            if retry_with_bedrock:
                logger.info("ğŸ”„ Retrying with Bedrock...")
                from lib.bedrock_client_enhanced import BedrockClientEnhanced
                bedrock_client = BedrockClientEnhanced()
                
                # í´ë°± ì•Œë¦¼
                yield "\n\n[ì‹œìŠ¤í…œ: í”„ë¦¬ë¯¸ì—„ ëª¨ë¸ ì œí•œìœ¼ë¡œ í‘œì¤€ ëª¨ë¸ë¡œ ì „í™˜ë©ë‹ˆë‹¤]\n\n"
                
                for chunk in bedrock_client.stream_bedrock(
                    user_message=enhanced_message,
                    engine_type=engine_type,
                    conversation_context=formatted_history,
                    user_role=user_role,
                    guidelines=prompt_data.get('instruction'),
                    description=prompt_data.get('description'),
                    files=prompt_data.get('files', [])
                ):
                    total_response += chunk
                    yield chunk

            # AI ì‘ë‹µ ì €ì¥ì€ message.pyì—ì„œ ì²˜ë¦¬í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì œê±°
            # ì¤‘ë³µ ì €ì¥ ë°©ì§€ë¥¼ ìœ„í•´ ì£¼ì„ ì²˜ë¦¬
            logger.info(f"AI response completed: {len(total_response)} chars (ì €ì¥ì€ message.pyì—ì„œ ì²˜ë¦¬)")

        except Exception as e:
            logger.error(f"Error streaming response: {str(e)}")
            raise

    def clear_history(self, conversation_id: str, user_id: str = None) -> bool:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"""
        try:
            self.conversation_manager.create_or_update_conversation(
                conversation_id=conversation_id,
                title="Cleared conversation",
                user_id=user_id
            )
            logger.info(f"Cleared history for conversation {conversation_id}")
            return True
        except Exception as e:
            logger.error(f"Error clearing history: {str(e)}")
            return False

    def track_usage(
        self,
        user_id: str,
        engine_type: str,
        input_text: str,
        output_text: str
    ) -> None:
        """ì‚¬ìš©ëŸ‰ ì¶”ì """
        try:
            # í† í° ê³„ì‚° (ê°„ë‹¨í•œ ì¶”ì •)
            input_tokens = len(input_text.split())
            output_tokens = len(output_text.split())

            logger.info(f"Usage tracked - User: {user_id}, Engine: {engine_type}")
            logger.info(f"Tokens - Input: {input_tokens}, Output: {output_tokens}")

            # DynamoDBì— ì‚¬ìš©ëŸ‰ ì €ì¥
            usage_table = dynamodb.Table(os.environ.get('USAGE_TABLE', 'p2-two-usage-two'))
            today = datetime.now().strftime('%Y-%m-%d')

            date_key = f"{today}#{engine_type}"

            from decimal import Decimal
            usage_table.update_item(
                Key={
                    'userId': user_id,
                    'date': date_key
                },
                UpdateExpression="""
                    ADD totalTokens :total,
                        inputTokens :input,
                        outputTokens :output,
                        messageCount :one
                    SET updatedAt = :timestamp,
                        lastUsedAt = :timestamp,
                        engineType = if_not_exists(engineType, :engineType),
                        usageDate = if_not_exists(usageDate, :usageDate)
                """,
                ExpressionAttributeValues={
                    ':total': Decimal(str(input_tokens + output_tokens)),
                    ':input': Decimal(str(input_tokens)),
                    ':output': Decimal(str(output_tokens)),
                    ':one': Decimal('1'),
                    ':timestamp': datetime.utcnow().isoformat() + 'Z',
                    ':engineType': engine_type,
                    ':usageDate': today
                }
            )

            logger.info("Usage recorded in DynamoDB")

        except Exception as e:
            logger.error(f"Error tracking usage: {str(e)}")

    def _merge_conversation_history(
        self,
        client_history: List[Dict],
        db_history: List[Dict]
    ) -> List[Dict]:
        """í´ë¼ì´ì–¸íŠ¸ì™€ DB íˆìŠ¤í† ë¦¬ ë³‘í•©"""
        merged = []
        seen_ids = set()

        # DB íˆìŠ¤í† ë¦¬ ë¨¼ì € ì¶”ê°€
        for msg in db_history:
            msg_id = msg.get('messageId', f"{msg.get('timestamp', '')}_{msg.get('role', '')}")
            if msg_id not in seen_ids:
                merged.append(msg)
                seen_ids.add(msg_id)

        # í´ë¼ì´ì–¸íŠ¸ íˆìŠ¤í† ë¦¬ ì¶”ê°€ (ì¤‘ë³µ ì œê±°)
        for msg in client_history:
            msg_id = f"{msg.get('timestamp', '')}_{msg.get('role', '')}"
            if msg_id not in seen_ids:
                merged.append(msg)
                seen_ids.add(msg_id)

        # ì‹œê°„ìˆœ ì •ë ¬
        merged.sort(key=lambda x: x.get('timestamp', ''))

        return merged[-20:]  # ìµœê·¼ 20ê°œë§Œ ìœ ì§€

    def _format_conversation_for_bedrock(self, conversation_history: List[Dict]) -> str:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ Bedrock í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…"""
        if not conversation_history:
            return ""

        formatted = []
        for msg in conversation_history[-10:]:  # ìµœê·¼ 10ê°œ ë©”ì‹œì§€ë§Œ
            role = msg.get('role', 'user')
            content = msg.get('content', '')

            if role == 'user':
                formatted.append(f"ì‚¬ìš©ì: {content}")
            elif role == 'assistant':
                formatted.append(f"AI: {content}")

        return "\n\n".join(formatted) if formatted else ""