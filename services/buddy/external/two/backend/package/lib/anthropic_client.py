"""
Anthropic API í´ë¼ì´ì–¸íŠ¸ - AWS Bedrock ëŒ€ì²´/ë³‘í–‰ìš©
Claude Opus 4.5 API ì§ì ‘ í˜¸ì¶œ ì§€ì›
"""
import json
import logging
import os
import sys
import time
import requests
from typing import Dict, Any, Iterator, List, Optional
from datetime import datetime, timezone, timedelta
import boto3
from botocore.exceptions import ClientError

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from src.config.aws import AWS_REGION
from utils.logger import setup_logger

logger = setup_logger(__name__)

# Secrets Manager í´ë¼ì´ì–¸íŠ¸
secrets_client = boto3.client('secretsmanager', region_name=AWS_REGION)

# Anthropic API ì„¤ì •
ANTHROPIC_API_URL = "https://api.anthropic.com/v1/messages"
ANTHROPIC_API_VERSION = "2023-06-01"

# ëª¨ë¸ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ë¡œ ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥)
DEFAULT_MODEL = "claude-3-5-sonnet-20241022"  # ê¸°ë³¸ê°’ (Sonnet ì‚¬ìš©)
OPUS_MODEL = os.environ.get('ANTHROPIC_MODEL_ID', 'claude-3-opus-20240229')  # Opus 4.5

# í† í° ì„¤ì •
MAX_TOKENS = int(os.environ.get('MAX_TOKENS', '4096'))
TEMPERATURE = float(os.environ.get('TEMPERATURE', '0.3'))
TOP_P = float(os.environ.get('TOP_P', '0.95'))
TOP_K = int(os.environ.get('TOP_K', '40'))

# Rate limit ì„¤ì •
RATE_LIMIT_DELAY = 1.0  # ìš”ì²­ ê°„ ìµœì†Œ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
MAX_RETRIES = 3
RETRY_DELAY = 60  # Rate limit ì‹œ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)

class AnthropicClient:
    """Anthropic API í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self):
        """í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        self.api_key = self._get_api_key()
        self.last_request_time = 0
        self.model_id = self._get_model_id()
        logger.info(f"AnthropicClient initialized with model: {self.model_id}")
    
    def _get_model_id(self) -> str:
        """ì‚¬ìš©í•  ëª¨ë¸ ID ê²°ì •"""
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ëª¨ë¸ ì„ íƒ
        use_opus = os.environ.get('USE_OPUS_MODEL', 'true').lower() == 'true'
        
        if use_opus:
            return OPUS_MODEL
        return DEFAULT_MODEL
    
    def _get_api_key(self) -> str:
        """AWS Secrets Managerì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°"""
        try:
            secret_name = os.environ.get('ANTHROPIC_SECRET_NAME', 'anthropic-api-key')
            
            response = secrets_client.get_secret_value(SecretId=secret_name)
            secret = json.loads(response['SecretString'])
            
            # API í‚¤ ì¶”ì¶œ (ë‹¤ì–‘í•œ í‚¤ ì´ë¦„ ì§€ì›)
            api_key = (secret.get('api_key') or 
                      secret.get('API_KEY') or 
                      secret.get('anthropic_api_key') or
                      secret.get('ANTHROPIC_API_KEY'))
            
            if not api_key:
                raise ValueError(f"API key not found in secret: {secret_name}")
            
            logger.info(f"âœ… API key loaded from Secrets Manager: {secret_name}")
            return api_key
            
        except ClientError as e:
            logger.error(f"Failed to get API key from Secrets Manager: {str(e)}")
            # í™˜ê²½ë³€ìˆ˜ í´ë°± (ê°œë°œìš©)
            api_key = os.environ.get('ANTHROPIC_API_KEY')
            if api_key:
                logger.warning("âš ï¸ Using API key from environment variable (not recommended for production)")
                return api_key
            raise ValueError("Anthropic API key not found in Secrets Manager or environment")
    
    def _apply_rate_limit(self):
        """Rate limit ì ìš©"""
        current_time = time.time()
        time_since_last = current_time - self.last_request_time
        
        if time_since_last < RATE_LIMIT_DELAY:
            sleep_time = RATE_LIMIT_DELAY - time_since_last
            logger.debug(f"Rate limiting: sleeping for {sleep_time:.2f} seconds")
            time.sleep(sleep_time)
        
        self.last_request_time = time.time()
    
    def _make_request(self, messages: List[Dict], system: str, stream: bool = False) -> Any:
        """API ìš”ì²­ ì‹¤í–‰"""
        headers = {
            "x-api-key": self.api_key,
            "anthropic-version": ANTHROPIC_API_VERSION,
            "content-type": "application/json"
        }
        
        body = {
            "model": self.model_id,
            "max_tokens": MAX_TOKENS,
            "temperature": TEMPERATURE,
            "top_p": TOP_P,
            "top_k": TOP_K,
            "messages": messages,
            "system": system,
            "stream": stream
        }
        
        # Rate limit ì ìš©
        self._apply_rate_limit()
        
        # ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­
        if stream:
            response = requests.post(
                ANTHROPIC_API_URL,
                headers=headers,
                json=body,
                stream=True,
                timeout=30
            )
            return response
        
        # ì¼ë°˜ ìš”ì²­
        response = requests.post(
            ANTHROPIC_API_URL,
            headers=headers,
            json=body,
            timeout=30
        )
        
        if response.status_code == 200:
            return response.json()
        else:
            self._handle_error(response)
    
    def _handle_error(self, response):
        """API ì˜¤ë¥˜ ì²˜ë¦¬"""
        error_msg = f"API request failed: {response.status_code}"
        
        try:
            error_data = response.json()
            error_msg = f"{error_msg} - {error_data.get('error', {}).get('message', response.text)}"
        except:
            error_msg = f"{error_msg} - {response.text}"
        
        # Rate limit ì˜¤ë¥˜
        if response.status_code == 429:
            logger.warning(f"Rate limit exceeded: {error_msg}")
            raise RateLimitError(error_msg)
        
        # ê¸°íƒ€ ì˜¤ë¥˜
        logger.error(error_msg)
        raise Exception(error_msg)
    
    def stream_response(
        self,
        user_message: str,
        system_prompt: str,
        conversation_history: Optional[List[Dict]] = None,
        enable_caching: bool = True
    ) -> Iterator[str]:
        """
        ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± (Bedrock ì¸í„°í˜ì´ìŠ¤ì™€ í˜¸í™˜)
        
        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            conversation_history: ëŒ€í™” ì´ë ¥
            enable_caching: ìºì‹± í™œì„±í™” ì—¬ë¶€ (Anthropic APIëŠ” ìë™ ìºì‹±)
        
        Yields:
            ì‘ë‹µ í…ìŠ¤íŠ¸ ì²­í¬
        """
        retry_count = 0
        
        while retry_count < MAX_RETRIES:
            try:
                # ë©”ì‹œì§€ êµ¬ì„±
                messages = conversation_history if conversation_history else []
                messages.append({"role": "user", "content": user_message})
                
                logger.info(f"ğŸ“¤ Calling Anthropic API with model: {self.model_id}")
                
                # API í˜¸ì¶œ (ìŠ¤íŠ¸ë¦¬ë°)
                response = self._make_request(
                    messages=messages,
                    system=system_prompt,
                    stream=True
                )
                
                # ì‘ë‹µ ì²´í¬
                if response.status_code != 200:
                    self._handle_error(response)
                
                # ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
                for line in response.iter_lines():
                    if line:
                        line_str = line.decode('utf-8')
                        
                        # SSE í˜•ì‹ íŒŒì‹±
                        if line_str.startswith('data: '):
                            data_str = line_str[6:]  # "data: " ì œê±°
                            
                            if data_str == '[DONE]':
                                logger.info("âœ… Streaming completed")
                                return
                            
                            try:
                                data = json.loads(data_str)
                                
                                # ë©”ì‹œì§€ ì‹œì‘
                                if data.get('type') == 'message_start':
                                    message = data.get('message', {})
                                    usage = message.get('usage', {})
                                    if usage:
                                        logger.info(f"ğŸ“Š Token usage - input: {usage.get('input_tokens', 0)}, "
                                                   f"output: {usage.get('output_tokens', 0)}")
                                
                                # ì»¨í…ì¸  ë¸íƒ€
                                elif data.get('type') == 'content_block_delta':
                                    delta = data.get('delta', {})
                                    if delta.get('type') == 'text_delta':
                                        text = delta.get('text', '')
                                        if text:
                                            yield text
                                
                                # ë©”ì‹œì§€ ì¢…ë£Œ
                                elif data.get('type') == 'message_stop':
                                    logger.info("âœ… Message complete")
                                    return
                                
                                # ì˜¤ë¥˜
                                elif data.get('type') == 'error':
                                    error = data.get('error', {})
                                    raise Exception(f"Stream error: {error.get('message', 'Unknown error')}")
                                    
                            except json.JSONDecodeError:
                                logger.warning(f"Failed to parse SSE data: {data_str[:100]}")
                                continue
                
                return
                
            except RateLimitError as e:
                retry_count += 1
                if retry_count >= MAX_RETRIES:
                    logger.error(f"Max retries exceeded for rate limit")
                    
                    # Bedrock í´ë°± ì˜µì…˜ ì²´í¬
                    if os.environ.get('FALLBACK_TO_BEDROCK', 'false').lower() == 'true':
                        logger.info("ğŸ”„ Falling back to Bedrock...")
                        yield "[Rate limit ì´ˆê³¼ - Bedrockìœ¼ë¡œ ì „í™˜]"
                        raise  # ìƒìœ„ í•¸ë“¤ëŸ¬ì—ì„œ Bedrockìœ¼ë¡œ ì²˜ë¦¬
                    else:
                        yield f"\n\n[ì˜¤ë¥˜] API rate limit ì´ˆê³¼. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                        return
                
                wait_time = RETRY_DELAY * retry_count
                logger.warning(f"Rate limit hit, waiting {wait_time} seconds... (retry {retry_count}/{MAX_RETRIES})")
                time.sleep(wait_time)
                
            except Exception as e:
                logger.error(f"Error in stream_response: {str(e)}")
                yield f"\n\n[ì˜¤ë¥˜] AI ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}"
                return
    
    def stream_bedrock(
        self,
        user_message: str,
        engine_type: str,
        conversation_context: str = "",
        user_role: str = 'user',
        guidelines: Optional[str] = None,
        description: Optional[str] = None,
        files: Optional[List[Dict]] = None
    ) -> Iterator[str]:
        """
        Bedrock í˜¸í™˜ ì¸í„°í˜ì´ìŠ¤
        BedrockClientEnhanced.stream_bedrock()ê³¼ ë™ì¼í•œ ì‹œê·¸ë‹ˆì²˜
        
        ì´ ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ë©´ ê¸°ì¡´ Bedrock ì½”ë“œë¥¼ ìˆ˜ì • ì—†ì´ 
        Anthropic APIë¡œ ì „í™˜ ê°€ëŠ¥
        """
        try:
            # Bedrock ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ë¥¼ Anthropic ìŠ¤íƒ€ì¼ë¡œ ë³€í™˜
            from lib.bedrock_client_enhanced import create_enhanced_system_prompt
            
            prompt_data = {
                'prompt': {
                    'instruction': guidelines or "",
                    'description': description or ""
                },
                'files': files or [],
                'userRole': user_role
            }
            
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„± (Bedrockê³¼ ë™ì¼í•œ ë¡œì§ ì‚¬ìš©)
            system_prompt = create_enhanced_system_prompt(
                prompt_data,
                engine_type,
                use_enhanced=True,
                flexibility_level="strict"
            )
            
            # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ í¬í•¨
            enhanced_message = self._create_message_with_context(
                user_message,
                conversation_context
            )
            
            logger.info(f"ğŸš€ Anthropic API streaming - Engine: {engine_type}, Role: {user_role}")
            
            # Anthropic API í˜¸ì¶œ
            for chunk in self.stream_response(
                user_message=enhanced_message,
                system_prompt=system_prompt,
                enable_caching=True
            ):
                yield chunk
                
        except Exception as e:
            logger.error(f"Error in stream_bedrock compatibility: {str(e)}")
            
            # Bedrock í´ë°±
            if os.environ.get('FALLBACK_TO_BEDROCK', 'false').lower() == 'true':
                logger.info("ğŸ”„ Falling back to Bedrock due to error...")
                raise  # ìƒìœ„ í•¸ë“¤ëŸ¬ì—ì„œ ì²˜ë¦¬
            else:
                yield f"\n\n[ì˜¤ë¥˜] ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}"
    
    def _create_message_with_context(self, user_message: str, conversation_context: str) -> str:
        """ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ ë©”ì‹œì§€ì— í¬í•¨"""
        # í•œêµ­ ì‹œê°„ (UTC+9)
        kst = timezone(timedelta(hours=9))
        current_time = datetime.now(kst)
        
        # ë™ì  ì»¨í…ìŠ¤íŠ¸ ì •ë³´
        context_info = f"""[í˜„ì¬ ì„¸ì…˜ ì •ë³´]
í˜„ì¬ ì‹œê°„: {current_time.strftime('%Y-%m-%d %H:%M:%S KST')}
ì‚¬ìš©ì ìœ„ì¹˜: ëŒ€í•œë¯¼êµ­
íƒ€ì„ì¡´: Asia/Seoul (KST)

â€» ì‹œê°„ ê´€ë ¨ ì§ˆë¬¸ì´ ìˆìœ¼ë©´ ìœ„ì˜ í˜„ì¬ ì‹œê°„ì„ ì°¸ì¡°í•˜ì„¸ìš”.
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

"""
        
        if conversation_context:
            return f"""{context_info}{conversation_context}

ìœ„ì˜ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ìì˜ ì§ˆë¬¸: {user_message}
"""
        return f"""{context_info}ì‚¬ìš©ìì˜ ì§ˆë¬¸: {user_message}"""


class RateLimitError(Exception):
    """Rate limit ì˜¤ë¥˜"""
    pass


def get_ai_client(prefer_anthropic: bool = None):
    """
    í™˜ê²½ ì„¤ì •ì— ë”°ë¼ ì ì ˆí•œ AI í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜
    
    Args:
        prefer_anthropic: Trueë©´ Anthropic, Falseë©´ Bedrock, Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ ì°¸ì¡°
    
    Returns:
        AnthropicClient ë˜ëŠ” BedrockClientEnhanced ì¸ìŠ¤í„´ìŠ¤
    """
    try:
        # ëª…ì‹œì  ì„ íƒì´ ìˆìœ¼ë©´ ìš°ì„ 
        if prefer_anthropic is not None:
            use_anthropic = prefer_anthropic
        else:
            # í™˜ê²½ë³€ìˆ˜ í™•ì¸
            use_anthropic = os.environ.get('USE_ANTHROPIC_API', 'false').lower() == 'true'
        
        if use_anthropic:
            logger.info("ğŸ¯ Using Anthropic API")
            return AnthropicClient()
        else:
            logger.info("ğŸ¯ Using AWS Bedrock")
            from lib.bedrock_client_enhanced import BedrockClientEnhanced
            return BedrockClientEnhanced()
            
    except Exception as e:
        logger.error(f"Failed to initialize AI client: {str(e)}")
        # ê¸°ë³¸ê°’ìœ¼ë¡œ Bedrock ì‚¬ìš©
        logger.info("âš ï¸ Falling back to Bedrock due to initialization error")
        from lib.bedrock_client_enhanced import BedrockClientEnhanced
        return BedrockClientEnhanced()


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    client = AnthropicClient()
    
    test_message = "ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë–¤ê°€ìš”?"
    test_prompt = "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."
    
    print("Testing Anthropic API streaming...")
    for chunk in client.stream_response(test_message, test_prompt):
        print(chunk, end='', flush=True)
    print("\nâœ… Test completed")