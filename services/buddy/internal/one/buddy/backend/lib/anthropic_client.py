"""
Anthropic API í´ë¼ì´ì–¸íŠ¸ - AWS Bedrock ëŒ€ì²´/ë³‘í–‰ìš©
Claude Opus 4.5 API ì§ì ‘ í˜¸ì¶œ ì§€ì›
"""
import json
import logging
import os
import sys
import time
import requests
import uuid
from typing import Dict, Any, Iterator, List, Optional
from datetime import datetime, timezone, timedelta
import boto3
from botocore.exceptions import ClientError

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from src.config.aws import AWS_REGION
from utils.logger import setup_logger

logger = setup_logger(__name__)

# Secrets Manager í´ë¼ì´ì–¸íŠ¸
secrets_client = boto3.client('secretsmanager', region_name=AWS_REGION)

# Anthropic API ì„¤ì •
ANTHROPIC_API_URL = "https://api.anthropic.com/v1/messages"
ANTHROPIC_API_VERSION = "2023-06-01"

# ëª¨ë¸ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ë¡œ ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥)
DEFAULT_MODEL = "claude-3-5-sonnet-20241022"  # ê¸°ë³¸ê°’ (Sonnet ì‚¬ìš©)
OPUS_MODEL = os.environ.get('ANTHROPIC_MODEL_ID', 'claude-opus-4-5-20251101')  # Opus 4.5 ìµœì‹  ë²„ì „

# í† í° ì„¤ì •
MAX_TOKENS = int(os.environ.get('MAX_TOKENS', '4096'))
TEMPERATURE = float(os.environ.get('TEMPERATURE', '0.3'))
TOP_P = float(os.environ.get('TOP_P', '0.95'))
TOP_K = int(os.environ.get('TOP_K', '40'))

# ë¹„ìš© ê³„ì‚° ìƒìˆ˜ (Claude Opus 4.5 ê¸°ì¤€, USD per 1M tokens)
PRICE_INPUT = 5.0  # Base Input Tokens
PRICE_OUTPUT = 25.0  # Output Tokens 
PRICE_CACHE_WRITE = 10.0  # 1h Cache Writes
PRICE_CACHE_READ = 0.50  # Cache Hits

# Rate limit ì„¤ì •
RATE_LIMIT_DELAY = 1.0  # ìš”ì²­ ê°„ ìµœì†Œ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
MAX_RETRIES = 3
RETRY_DELAY = 60  # Rate limit ì‹œ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)

class AnthropicClient:
    """Anthropic API í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self):
        """í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        self.api_key = self._get_api_key()
        self.last_request_time = 0
        self.model_id = self._get_model_id()
        self.service_name = os.environ.get('SERVICE_NAME', 'buddy')  # ì„œë¹„ìŠ¤ ì‹ë³„ì
        self.max_tokens = MAX_TOKENS
        self.temperature = TEMPERATURE
        # Usage ì¶”ì 
        self.last_usage = {}
        logger.info(f"AnthropicClient initialized with model: {self.model_id}, service: {self.service_name}")
    
    def _get_model_id(self) -> str:
        """ì‚¬ìš©í•  ëª¨ë¸ ID ê²°ì •"""
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ëª¨ë¸ ì„ íƒ
        use_opus = os.environ.get('USE_OPUS_MODEL', 'true').lower() == 'true'
        
        if use_opus:
            return OPUS_MODEL
        return DEFAULT_MODEL
    
    def _get_api_key(self) -> str:
        """AWS Secrets Managerì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°"""
        try:
            secret_name = os.environ.get('ANTHROPIC_SECRET_NAME', 'buddy-v1')
            
            response = secrets_client.get_secret_value(SecretId=secret_name)
            secret = json.loads(response['SecretString'])
            
            # API í‚¤ ì¶”ì¶œ (ë‹¤ì–‘í•œ í‚¤ ì´ë¦„ ì§€ì›)
            api_key = (secret.get('api_key') or 
                      secret.get('API_KEY') or 
                      secret.get('anthropic_api_key') or
                      secret.get('ANTHROPIC_API_KEY'))
            
            if not api_key:
                raise ValueError(f"API key not found in secret: {secret_name}")
            
            logger.info(f"âœ… API key loaded from Secrets Manager: {secret_name}")
            return api_key
            
        except ClientError as e:
            logger.error(f"Failed to get API key from Secrets Manager: {str(e)}")
            # í™˜ê²½ë³€ìˆ˜ í´ë°± (ê°œë°œìš©)
            api_key = os.environ.get('ANTHROPIC_API_KEY')
            if api_key:
                logger.warning("âš ï¸ Using API key from environment variable (not recommended for production)")
                return api_key
            raise ValueError("Anthropic API key not found in Secrets Manager or environment")
    
    def _apply_rate_limit(self):
        """Rate limit ì ìš©"""
        current_time = time.time()
        time_since_last = current_time - self.last_request_time
        
        if time_since_last < RATE_LIMIT_DELAY:
            sleep_time = RATE_LIMIT_DELAY - time_since_last
            logger.debug(f"Rate limiting: sleeping for {sleep_time:.2f} seconds")
            time.sleep(sleep_time)
        
        self.last_request_time = time.time()
    
    def _get_default_metadata(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ë©”íƒ€ë°ì´í„° ìƒì„±"""
        return {
            "user_id": self.service_name  # 'buddy' ì„œë¹„ìŠ¤ ì‹ë³„
        }
    
    def _make_request(self, messages: List[Dict], system: str, stream: bool = False, metadata: Optional[Dict] = None, enable_web_search: bool = False, enable_caching: bool = True) -> Any:
        """API ìš”ì²­ ì‹¤í–‰ (í”„ë¡¬í”„íŠ¸ ìºì‹± ì§€ì›)"""
        headers = {
            "x-api-key": self.api_key,
            "anthropic-version": ANTHROPIC_API_VERSION,
            "content-type": "application/json",
            "anthropic-beta": "prompt-caching-2024-07-31"  # ìºì‹± ë² íƒ€ ê¸°ëŠ¥ í™œì„±í™”
        }
        
        # í”„ë¡¬í”„íŠ¸ ìºì‹± ì ìš© (systemë§Œ ìºì‹±)
        if enable_caching:
            # System promptë¥¼ ìºì‹± ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
            system_content = [{
                "type": "text",
                "text": system,
                "cache_control": {"type": "ephemeral", "ttl": "1h"}  # 1ì‹œê°„ ìºì‹œ
            }]
        else:
            # ìºì‹± ë¹„í™œì„±í™” ì‹œ ê¸°ë³¸ í˜•íƒœ
            system_content = system
        
        # Claude 4.5 OpusëŠ” temperatureì™€ top_pë¥¼ ë™ì‹œì— ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ
        body = {
            "model": self.model_id,
            "max_tokens": MAX_TOKENS,
            "temperature": TEMPERATURE,  # temperatureë§Œ ì‚¬ìš©
            "messages": messages,
            "system": system_content,
            "stream": stream
        }
        
        # ì›¹ ê²€ìƒ‰ ë„êµ¬ í™œì„±í™” (ë² íƒ€ ê¸°ëŠ¥)
        if enable_web_search:
            body["tools"] = [
                {
                    "type": "web_search_20250305",
                    "name": "web_search",
                    "max_uses": 5  # ìµœëŒ€ 5ë²ˆê¹Œì§€ ì›¹ ê²€ìƒ‰ í—ˆìš©
                }
            ]
            logger.info("ğŸ” Web search tool enabled in API request")
        
        # top_këŠ” ì„ íƒì ìœ¼ë¡œ ì¶”ê°€ (Claude 4.5 Opusì—ì„œ ì§€ì›)
        if TOP_K > 0:
            body["top_k"] = TOP_K
        
        # ë©”íƒ€ë°ì´í„° ì¶”ê°€ (ì„œë¹„ìŠ¤ ì¶”ì ìš©)
        if metadata:
            body["metadata"] = metadata
        else:
            body["metadata"] = self._get_default_metadata()
        
        # Rate limit ì ìš©
        self._apply_rate_limit()
        
        # ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­
        if stream:
            response = requests.post(
                ANTHROPIC_API_URL,
                headers=headers,
                json=body,
                stream=True,
                timeout=30
            )
            return response
        
        # ì¼ë°˜ ìš”ì²­
        response = requests.post(
            ANTHROPIC_API_URL,
            headers=headers,
            json=body,
            timeout=30
        )
        
        if response.status_code == 200:
            return response.json()
        else:
            self._handle_error(response)
    
    def _handle_error(self, response):
        """API ì˜¤ë¥˜ ì²˜ë¦¬"""
        error_msg = f"API request failed: {response.status_code}"
        
        try:
            error_data = response.json()
            error_msg = f"{error_msg} - {error_data.get('error', {}).get('message', response.text)}"
        except:
            error_msg = f"{error_msg} - {response.text}"
        
        # Rate limit ì˜¤ë¥˜
        if response.status_code == 429:
            logger.warning(f"Rate limit exceeded: {error_msg}")
            raise RateLimitError(error_msg)
        
        # ê¸°íƒ€ ì˜¤ë¥˜
        logger.error(error_msg)
        raise Exception(error_msg)
    
    def stream_response(
        self,
        user_message: str,
        system_prompt: str,
        conversation_history: Optional[List[Dict]] = None,
        enable_caching: bool = True,
        enable_web_search: bool = False
    ) -> Iterator[str]:
        """
        ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± (Bedrock ì¸í„°í˜ì´ìŠ¤ì™€ í˜¸í™˜)
        
        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            conversation_history: ëŒ€í™” ì´ë ¥
            enable_caching: ìºì‹± í™œì„±í™” ì—¬ë¶€ (Anthropic APIëŠ” ìë™ ìºì‹±)
            enable_web_search: ì›¹ ê²€ìƒ‰ ë„êµ¬ í™œì„±í™” ì—¬ë¶€
        
        Yields:
            ì‘ë‹µ í…ìŠ¤íŠ¸ ì²­í¬
        """
        retry_count = 0
        
        while retry_count < MAX_RETRIES:
            try:
                # ë™ì  ì»¨í…ìŠ¤íŠ¸ë¥¼ user_messageì— ì¶”ê°€
                enhanced_user_message = self._create_dynamic_context() + user_message
                
                # ë©”ì‹œì§€ êµ¬ì„±
                messages = conversation_history if conversation_history else []
                messages.append({"role": "user", "content": enhanced_user_message})
                
                # ì›¹ ê²€ìƒ‰ í™œì„±í™” ì²´í¬
                use_web_search = enable_web_search or os.environ.get('ENABLE_NATIVE_WEB_SEARCH', 'false').lower() == 'true'
                
                # System prompt ì •ì  ë³€ìˆ˜ ì¹˜í™˜ (ìºì‹± ìµœì í™”)
                processed_system = self._replace_template_variables(system_prompt)
                
                logger.info(f"ğŸ“¤ Calling Anthropic API with model: {self.model_id}, service: {self.service_name}, web_search: {use_web_search}, caching: {enable_caching}")
                
                # API í˜¸ì¶œ (ìŠ¤íŠ¸ë¦¬ë°) - ë©”íƒ€ë°ì´í„°ì™€ ìºì‹± í¬í•¨
                response = self._make_request(
                    messages=messages,
                    system=processed_system,
                    stream=True,
                    metadata={"user_id": self.service_name},  # buddy ì„œë¹„ìŠ¤ ì‹ë³„
                    enable_web_search=use_web_search,
                    enable_caching=enable_caching
                )
                
                # ì‘ë‹µ ì²´í¬
                if response.status_code != 200:
                    self._handle_error(response)
                
                # ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
                for line in response.iter_lines():
                    if line:
                        line_str = line.decode('utf-8')
                        
                        # SSE í˜•ì‹ íŒŒì‹±
                        if line_str.startswith('data: '):
                            data_str = line_str[6:]  # "data: " ì œê±°
                            
                            if data_str == '[DONE]':
                                logger.info("âœ… Streaming completed")
                                return
                            
                            try:
                                data = json.loads(data_str)
                                
                                # ë©”ì‹œì§€ ì‹œì‘
                                if data.get('type') == 'message_start':
                                    message = data.get('message', {})
                                    usage = message.get('usage', {})
                                    if usage:
                                        # ìºì‹œ ê´€ë ¨ í† í° ì¶”ì¶œ
                                        cache_read = usage.get('cache_read_input_tokens', 0)
                                        cache_write = usage.get('cache_creation_input_tokens', 0)
                                        
                                        # Usage ì •ë³´ ì €ì¥
                                        self.last_usage = {
                                            'input_tokens': usage.get('input_tokens', 0),
                                            'output_tokens': usage.get('output_tokens', 0),
                                            'cache_read_input_tokens': cache_read,
                                            'cache_creation_input_tokens': cache_write
                                        }
                                        
                                        # ë¹„ìš© ê³„ì‚° ë° ë¡œê¹…
                                        cost = self._calculate_cost(self.last_usage)
                                        self.last_usage['total_cost'] = cost

                                        # ìºì‹œ HIT/MISS íŒì • ë° ë¡œê¹…
                                        if cache_read > 0:
                                            logger.info(f"ğŸ¯ PROMPT CACHE HIT! cache_read: {cache_read} tokens")
                                            # ë¹„ìš© ì ˆê° ê³„ì‚° (ìºì‹œ ì½ê¸°ëŠ” 90% í• ì¸)
                                            savings = (cache_read / 1_000_000) * (PRICE_INPUT - PRICE_CACHE_READ)
                                            logger.info(f"ğŸ’µ Estimated savings from cache: ${savings:.6f}")
                                        elif cache_write > 0:
                                            logger.info(f"ğŸ“ PROMPT CACHE MISS - cache_write: {cache_write} tokens (next request will hit)")

                                        logger.info(f"ğŸ’° Token Usage: input={usage.get('input_tokens', 0)}, "
                                                   f"output={usage.get('output_tokens', 0)}, "
                                                   f"cache_read={cache_read}, cache_write={cache_write}")
                                        logger.info(f"ğŸ’° API Cost: ${cost:.6f}")
                                
                                # ì»¨í…ì¸  ë¸íƒ€
                                elif data.get('type') == 'content_block_delta':
                                    delta = data.get('delta', {})
                                    if delta.get('type') == 'text_delta':
                                        text = delta.get('text', '')
                                        if text:
                                            yield text
                                
                                # ë©”ì‹œì§€ ì¢…ë£Œ
                                elif data.get('type') == 'message_stop':
                                    logger.info("âœ… Message complete")
                                    return
                                
                                # ì˜¤ë¥˜
                                elif data.get('type') == 'error':
                                    error = data.get('error', {})
                                    raise Exception(f"Stream error: {error.get('message', 'Unknown error')}")
                                    
                            except json.JSONDecodeError:
                                logger.warning(f"Failed to parse SSE data: {data_str[:100]}")
                                continue
                
                return
                
            except RateLimitError as e:
                retry_count += 1
                if retry_count >= MAX_RETRIES:
                    logger.error(f"Max retries exceeded for rate limit")
                    
                    # Bedrock í´ë°± ì˜µì…˜ ì²´í¬
                    if os.environ.get('FALLBACK_TO_BEDROCK', 'false').lower() == 'true':
                        logger.info("ğŸ”„ Falling back to Bedrock...")
                        yield "[Rate limit ì´ˆê³¼ - Bedrockìœ¼ë¡œ ì „í™˜]"
                        raise  # ìƒìœ„ í•¸ë“¤ëŸ¬ì—ì„œ Bedrockìœ¼ë¡œ ì²˜ë¦¬
                    else:
                        yield f"\n\n[ì˜¤ë¥˜] API rate limit ì´ˆê³¼. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                        return
                
                wait_time = RETRY_DELAY * retry_count
                logger.warning(f"Rate limit hit, waiting {wait_time} seconds... (retry {retry_count}/{MAX_RETRIES})")
                time.sleep(wait_time)
                
            except Exception as e:
                logger.error(f"Error in stream_response: {str(e)}")
                yield f"\n\n[ì˜¤ë¥˜] AI ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}"
                return
    
    def stream_bedrock(
        self,
        user_message: str,
        engine_type: str,
        conversation_context: str = "",
        user_role: str = 'user',
        guidelines: Optional[str] = None,
        description: Optional[str] = None,
        files: Optional[List[Dict]] = None,
        enable_web_search: bool = False
    ) -> Iterator[str]:
        """
        Bedrock í˜¸í™˜ ì¸í„°í˜ì´ìŠ¤
        BedrockClientEnhanced.stream_bedrock()ê³¼ ë™ì¼í•œ ì‹œê·¸ë‹ˆì²˜
        
        ì´ ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ë©´ ê¸°ì¡´ Bedrock ì½”ë“œë¥¼ ìˆ˜ì • ì—†ì´ 
        Anthropic APIë¡œ ì „í™˜ ê°€ëŠ¥
        """
        try:
            # Bedrock ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ë¥¼ Anthropic ìŠ¤íƒ€ì¼ë¡œ ë³€í™˜
            from lib.bedrock_client_enhanced import create_enhanced_system_prompt
            
            prompt_data = {
                'prompt': {
                    'instruction': guidelines or "",
                    'description': description or ""
                },
                'files': files or [],
                'userRole': user_role
            }
            
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„± (Bedrockê³¼ ë™ì¼í•œ ë¡œì§ ì‚¬ìš©)
            system_prompt = create_enhanced_system_prompt(
                prompt_data,
                engine_type,
                use_enhanced=True,
                flexibility_level="strict"
            )
            
            # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ í¬í•¨
            enhanced_message = self._create_message_with_context(
                user_message,
                conversation_context
            )
            
            logger.info(f"ğŸš€ Anthropic API streaming - Engine: {engine_type}, Role: {user_role}")
            
            # Anthropic API í˜¸ì¶œ
            for chunk in self.stream_response(
                user_message=enhanced_message,
                system_prompt=system_prompt,
                enable_caching=True
            ):
                yield chunk
                
        except Exception as e:
            logger.error(f"Error in stream_bedrock compatibility: {str(e)}")
            
            # Bedrock í´ë°±
            if os.environ.get('FALLBACK_TO_BEDROCK', 'false').lower() == 'true':
                logger.info("ğŸ”„ Falling back to Bedrock due to error...")
                raise  # ìƒìœ„ í•¸ë“¤ëŸ¬ì—ì„œ ì²˜ë¦¬
            else:
                yield f"\n\n[ì˜¤ë¥˜] ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}"
    
    def _calculate_cost(self, usage: Dict[str, int]) -> float:
        """ë¹„ìš© ê³„ì‚° (Claude Opus 4.5 ê¸°ì¤€)"""
        cost_input = (usage.get('input_tokens', 0) / 1_000_000) * PRICE_INPUT
        cost_output = (usage.get('output_tokens', 0) / 1_000_000) * PRICE_OUTPUT
        cost_cache_write = (usage.get('cache_creation_input_tokens', 0) / 1_000_000) * PRICE_CACHE_WRITE
        cost_cache_read = (usage.get('cache_read_input_tokens', 0) / 1_000_000) * PRICE_CACHE_READ
        
        return cost_input + cost_output + cost_cache_write + cost_cache_read
    
    def _create_dynamic_context(self) -> str:
        """ë™ì  ì»¨í…ìŠ¤íŠ¸ ìƒì„± (user_messageì— ì¶”ê°€ìš©) - ìºì‹± ìµœì í™”ë¥¼ ìœ„í•´ ì—¬ê¸°ì—ë§Œ ë™ì  ì •ë³´ í¬í•¨"""
        # í•œêµ­ ì‹œê°„ (UTC+9)
        kst = timezone(timedelta(hours=9))
        current_time = datetime.now(kst)

        return f"""[âš ï¸ ì¤‘ìš”: í˜„ì¬ ì„¸ì…˜ ì •ë³´ - ë°˜ë“œì‹œ ì°¸ê³ í•˜ì„¸ìš”]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“… í˜„ì¬ ì—°ë„: {current_time.year}ë…„
ğŸ“… ì˜¤ëŠ˜ ë‚ ì§œ: {current_time.strftime('%Yë…„ %mì›” %dì¼')}
ğŸ• í˜„ì¬ ì‹œê°„: {current_time.strftime('%Y-%m-%d %H:%M:%S KST')}
ğŸ“ ì‚¬ìš©ì ìœ„ì¹˜: ëŒ€í•œë¯¼êµ­ (Asia/Seoul)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âš ï¸ ì¤‘ìš”: ì‘ë‹µì—ì„œ ë‚ ì§œë‚˜ ì—°ë„ë¥¼ ì–¸ê¸‰í•  ë•Œ ë°˜ë“œì‹œ ìœ„ì˜ í˜„ì¬ ë‚ ì§œ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
2024ë…„ì´ë¼ê³  í•˜ì§€ ë§ˆì„¸ìš”. í˜„ì¬ëŠ” {current_time.year}ë…„ì…ë‹ˆë‹¤.

"""
    
    def _replace_template_variables(self, prompt: str) -> str:
        """ì •ì  ê°’ë§Œ ì¹˜í™˜ (ìºì‹± ìµœì í™”)"""
        replacements = {
            '{{user_location}}': 'ëŒ€í•œë¯¼êµ­',
            '{{timezone}}': 'Asia/Seoul (KST)'
        }
        
        for key, value in replacements.items():
            prompt = prompt.replace(key, value)
        
        return prompt
    
    def _create_message_with_context(self, user_message: str, conversation_context: str) -> str:
        """ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ ë©”ì‹œì§€ì— í¬í•¨ (ë™ì  ì»¨í…ìŠ¤íŠ¸ë§Œ)"""
        # ë™ì  ì»¨í…ìŠ¤íŠ¸ëŠ” user_messageì—ë§Œ ì¶”ê°€ (ìºì‹œ ë¬´íš¨í™” ë°©ì§€)
        dynamic_context = self._create_dynamic_context()
        
        context_info = f"""{dynamic_context}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

"""
        
        if conversation_context:
            return f"""{context_info}{conversation_context}

ìœ„ì˜ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ìì˜ ì§ˆë¬¸: {user_message}
"""
        return f"""{context_info}ì‚¬ìš©ìì˜ ì§ˆë¬¸: {user_message}"""


class RateLimitError(Exception):
    """Rate limit ì˜¤ë¥˜"""
    pass


def get_ai_client(prefer_anthropic: bool = None):
    """
    í™˜ê²½ ì„¤ì •ì— ë”°ë¼ ì ì ˆí•œ AI í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜
    
    Args:
        prefer_anthropic: Trueë©´ Anthropic, Falseë©´ Bedrock, Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ ì°¸ì¡°
    
    Returns:
        AnthropicClient ë˜ëŠ” BedrockClientEnhanced ì¸ìŠ¤í„´ìŠ¤
    """
    try:
        # ëª…ì‹œì  ì„ íƒì´ ìˆìœ¼ë©´ ìš°ì„ 
        if prefer_anthropic is not None:
            use_anthropic = prefer_anthropic
        else:
            # í™˜ê²½ë³€ìˆ˜ í™•ì¸
            use_anthropic = os.environ.get('USE_ANTHROPIC_API', 'false').lower() == 'true'
        
        if use_anthropic:
            logger.info("ğŸ¯ Using Anthropic API")
            return AnthropicClient()
        else:
            logger.info("ğŸ¯ Using AWS Bedrock")
            from lib.bedrock_client_enhanced import BedrockClientEnhanced
            return BedrockClientEnhanced()
            
    except Exception as e:
        logger.error(f"Failed to initialize AI client: {str(e)}")
        # ê¸°ë³¸ê°’ìœ¼ë¡œ Bedrock ì‚¬ìš©
        logger.info("âš ï¸ Falling back to Bedrock due to initialization error")
        from lib.bedrock_client_enhanced import BedrockClientEnhanced
        return BedrockClientEnhanced()


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    client = AnthropicClient()
    
    test_message = "ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë–¤ê°€ìš”?"
    test_prompt = "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."
    
    print("Testing Anthropic API streaming...")
    for chunk in client.stream_response(test_message, test_prompt):
        print(chunk, end='', flush=True)
    print("\nâœ… Test completed")